{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c5dd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LICENSE',\n",
       " 'requirements.txt',\n",
       " 'code',\n",
       " 'README.md',\n",
       " '.gitignore',\n",
       " '.git',\n",
       " 'data',\n",
       " 'notebooks']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "os.listdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04370aa",
   "metadata": {},
   "source": [
    "| Field            | Type   | Explanation                                                                 |\n",
    "|------------------|--------|------------------------------------------------------------------------------|\n",
    "| main_category    | str    | Main category (i.e., domain) of the product.                                 |\n",
    "| title            | str    | Name of the product.                                                         |\n",
    "| average_rating   | float  | Rating of the product shown on the product page.                             |\n",
    "| rating_number    | int    | Number of ratings in the product.                                            |\n",
    "| features         | list   | Bullet-point format features of the product.                                 |\n",
    "| description      | list   | Description of the product.                                                  |\n",
    "| price            | float  | Price in US dollars (at time of crawling).                                   |\n",
    "| images           | list   | Images of the product. Each image has different sizes (thumb, large, hi_res). The “variant” field shows the position of image. |\n",
    "| videos           | list   | Videos of the product including title and url.                               |\n",
    "| store            | str    | Store name of the product.                                                   |\n",
    "| categories       | list   | Hierarchical categories of the product.                                      |\n",
    "| details          | dict   | Product details, including materials, brand, sizes, etc.                     |\n",
    "| parent_asin      | str    | Parent ID of the product.                                                    |\n",
    "| bought_together  | list   | Recommended bundles from the websites.                                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aeb45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/Books_10k.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c74d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329af501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(rating, numeric=False):\n",
    "    mapping = {\n",
    "        \"negative\": 0,\n",
    "        \"neutral\": 1,\n",
    "        \"positive\": 2\n",
    "    }\n",
    "    \n",
    "    if pd.isna(rating):\n",
    "        return None\n",
    "    \n",
    "    if rating <= 2:\n",
    "        sentiment = \"negative\"\n",
    "    elif rating == 3:\n",
    "        sentiment = \"neutral\"\n",
    "    else:\n",
    "        sentiment = \"positive\"\n",
    "    \n",
    "    return mapping[sentiment] if numeric else sentiment\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data[\"sentiment_str\"] = data[\"rating\"].apply(lambda x: map_sentiment(x, numeric=False))\n",
    "data[\"sentiment\"] = data[\"rating\"].apply(lambda x: map_sentiment(x, numeric=True))\n",
    "\n",
    "df = data.dropna(subset=[\"rating\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27eecfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>sentiment_str</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Missing the sketch pad</td>\n",
       "      <td>Missing the sketch pad. Even worse I realized ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1631591290</td>\n",
       "      <td>1631591290</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2021-08-05 04:28:04.910</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Crease down entire side of every page!!!</td>\n",
       "      <td>Every page has a crease running the entire len...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2021-01-26 01:07:03.325</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Written From a Lens of Fear.</td>\n",
       "      <td>Only read and believe things you want to see c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0929385225</td>\n",
       "      <td>0929385225</td>\n",
       "      <td>AG2L7H23R5LLKDKLBEF2Q3L2MVDA</td>\n",
       "      <td>2021-04-05 01:16:52.328</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Good if your little one is unsure/scared of th...</td>\n",
       "      <td>My little one just likes doctors so I thought ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0593426452</td>\n",
       "      <td>0593426452</td>\n",
       "      <td>AE74DYR3QUGVPZJ3P7RFWBGIX7XQ</td>\n",
       "      <td>2022-03-18 04:24:46.871</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>Worth every cent I paid</td>\n",
       "      <td>Apparently there are readers who enjoyed this ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00AAGZ1S0</td>\n",
       "      <td>B00AAGZ1S0</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2013-06-24 00:18:07.000</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2</td>\n",
       "      <td>Confusing</td>\n",
       "      <td>The story takes place over the past fifty year...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0544077792</td>\n",
       "      <td>0544077792</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2013-03-28 02:06:55.000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2</td>\n",
       "      <td>The Case of the Missing Plot</td>\n",
       "      <td>I picked this up because the premise sounded i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B0048EL7YW</td>\n",
       "      <td>B0048EL7YW</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-12-05 19:07:48.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>Poorly written biography of a fascinating woman</td>\n",
       "      <td>Calling Julia Child 'remarkable' is an underst...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0307272222</td>\n",
       "      <td>0307272222</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-12-01 19:41:44.000</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr von Igelfeld afield</td>\n",
       "      <td>Professor Dr Moritz-Maria von Igelfeld leaves ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-11-17 23:52:38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                              title  \\\n",
       "0          1      Not a watercolor book! Seems like copies imo.   \n",
       "1          1                             Missing the sketch pad   \n",
       "2          1           Crease down entire side of every page!!!   \n",
       "3          1                       Written From a Lens of Fear.   \n",
       "4          1  Good if your little one is unsure/scared of th...   \n",
       "...      ...                                                ...   \n",
       "9995       2                            Worth every cent I paid   \n",
       "9996       2                                          Confusing   \n",
       "9997       2                       The Case of the Missing Plot   \n",
       "9998       2    Poorly written biography of a fascinating woman   \n",
       "9999       2                             Dr von Igelfeld afield   \n",
       "\n",
       "                                                   text  \\\n",
       "0     It is definitely not a watercolor book.  The p...   \n",
       "1     Missing the sketch pad. Even worse I realized ...   \n",
       "2     Every page has a crease running the entire len...   \n",
       "3     Only read and believe things you want to see c...   \n",
       "4     My little one just likes doctors so I thought ...   \n",
       "...                                                 ...   \n",
       "9995  Apparently there are readers who enjoyed this ...   \n",
       "9996  The story takes place over the past fifty year...   \n",
       "9997  I picked this up because the premise sounded i...   \n",
       "9998  Calling Julia Child 'remarkable' is an underst...   \n",
       "9999  Professor Dr Moritz-Maria von Igelfeld leaves ...   \n",
       "\n",
       "                                                 images        asin  \\\n",
       "0     [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB   \n",
       "1                                                    []  1631591290   \n",
       "2     [{'small_image_url': 'https://images-na.ssl-im...  1780671067   \n",
       "3                                                    []  0929385225   \n",
       "4                                                    []  0593426452   \n",
       "...                                                 ...         ...   \n",
       "9995                                                 []  B00AAGZ1S0   \n",
       "9996                                                 []  0544077792   \n",
       "9997                                                 []  B0048EL7YW   \n",
       "9998                                                 []  0307272222   \n",
       "9999                                                 []  1400095093   \n",
       "\n",
       "     parent_asin                       user_id               timestamp  \\\n",
       "0     B09BGPFTDB  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485   \n",
       "1     1631591290  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2021-08-05 04:28:04.910   \n",
       "2     1780671067  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2021-01-26 01:07:03.325   \n",
       "3     0929385225  AG2L7H23R5LLKDKLBEF2Q3L2MVDA 2021-04-05 01:16:52.328   \n",
       "4     0593426452  AE74DYR3QUGVPZJ3P7RFWBGIX7XQ 2022-03-18 04:24:46.871   \n",
       "...          ...                           ...                     ...   \n",
       "9995  B00AAGZ1S0  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2013-06-24 00:18:07.000   \n",
       "9996  0544077792  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2013-03-28 02:06:55.000   \n",
       "9997  B0048EL7YW  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-12-05 19:07:48.000   \n",
       "9998  0307272222  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-12-01 19:41:44.000   \n",
       "9999  1400095093  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-11-17 23:52:38.000   \n",
       "\n",
       "      helpful_vote  verified_purchase sentiment_str  sentiment  \n",
       "0                0               True      negative          0  \n",
       "1                0               True      negative          0  \n",
       "2                2               True      negative          0  \n",
       "3                0              False      negative          0  \n",
       "4                1               True      negative          0  \n",
       "...            ...                ...           ...        ...  \n",
       "9995             2               True      negative          0  \n",
       "9996             1              False      negative          0  \n",
       "9997             0              False      negative          0  \n",
       "9998            37              False      negative          0  \n",
       "9999             0              False      negative          0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb8814",
   "metadata": {},
   "source": [
    "### MANCA CONTROLLARE DUPLICATI !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d594013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>sentiment_str</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1</td>\n",
       "      <td>Deserves ZERO stars</td>\n",
       "      <td>Poorly written.  Not much useful information. ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B0BMT2PL6G</td>\n",
       "      <td>B0BMT2PL6G</td>\n",
       "      <td>AFZGIAQOQORI5HDS22LMNLE422OA</td>\n",
       "      <td>2023-02-21 19:38:52.495</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1</td>\n",
       "      <td>Save your money</td>\n",
       "      <td>What good is a map if you can' t read it?  Man...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1440354642</td>\n",
       "      <td>1440354642</td>\n",
       "      <td>AFZGIAQOQORI5HDS22LMNLE422OA</td>\n",
       "      <td>2022-10-25 11:47:04.661</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating                title  \\\n",
       "699       1  Deserves ZERO stars   \n",
       "700       1      Save your money   \n",
       "\n",
       "                                                  text images        asin  \\\n",
       "699  Poorly written.  Not much useful information. ...     []  B0BMT2PL6G   \n",
       "700  What good is a map if you can' t read it?  Man...     []  1440354642   \n",
       "\n",
       "    parent_asin                       user_id               timestamp  \\\n",
       "699  B0BMT2PL6G  AFZGIAQOQORI5HDS22LMNLE422OA 2023-02-21 19:38:52.495   \n",
       "700  1440354642  AFZGIAQOQORI5HDS22LMNLE422OA 2022-10-25 11:47:04.661   \n",
       "\n",
       "     helpful_vote  verified_purchase sentiment_str  sentiment  \n",
       "699             0               True      negative          0  \n",
       "700             0               True      negative          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(subset=['user_id', 'asin', 'parent_asin'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5c83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_array'] = df['text'].str.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1a8d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is definitely not a watercolor book.  The paper bucked completely.  The pages honestly appear to be photo copies of other pictures. I say that bc if you look at the seal pics you can see the tell tale line at the bottom of the page.  As someone who has made many photocopies of pages in my time so I could try out different colors & mediums that black line is a dead giveaway to me. It’s on other pages too.  The entire book just seems off. Nothing is sharp & clear. There is what looks like toner dust on all the pages making them look muddy.  There are no sharp lines & there is no clear definition.  At least there isn’t in my copy.  And the Coloring Book for Adult on the bottom of the front cover annoys me. Why is it singular & not plural?  They usually say coloring book for kids or coloring book for kids & adults or coloring book for adults- plural.  Lol  Plus it would work for kids if you can get over the grey scale nature of it.  Personally I’m not going to waste expensive pens & paints trying to paint over the grey & black mess.  I grew up in SW Florida minutes from the beaches & I was really excited about the sea life in this. I hope the printers & designers figure out how to clean up the mess bc some of the designs are really cute. They just aren’t worth my time to hand trace & transfer them, but I’m sure there are ppl that will be up to the challenge.  This is one is a hard no. Going back. I tried.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.explode(column='text_array')['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511d5a1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mexplode(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: nltk\u001b[38;5;241m.\u001b[39msent_tokenize(x)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "df = df.explode(column=\"text\".apply(lambda x: nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08df21b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>It is definitely not a watercolor book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>The paper bucked completely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>The pages honestly appear to be photo copies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>I say that bc if you look at the seal pics yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>As someone who has made many photocopies of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr von Igelfeld afield</td>\n",
       "      <td>Professor Dr Moritz-Maria von Igelfeld leaves ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-11-17 23:52:38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Fans of McCall Smith's other serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr von Igelfeld afield</td>\n",
       "      <td>Professor Dr Moritz-Maria von Igelfeld leaves ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-11-17 23:52:38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>Dr von Igelfeld is not as nearly sympathetic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr von Igelfeld afield</td>\n",
       "      <td>Professor Dr Moritz-Maria von Igelfeld leaves ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-11-17 23:52:38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>Dr von Igelfeld's exploits lean more towards...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr von Igelfeld afield</td>\n",
       "      <td>Professor Dr Moritz-Maria von Igelfeld leaves ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-11-17 23:52:38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>Unlike the other series I am not particularl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr von Igelfeld afield</td>\n",
       "      <td>Professor Dr Moritz-Maria von Igelfeld leaves ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>1400095093</td>\n",
       "      <td>AHXWUCTMVBQXDVMDFPA3NO43QF2Q</td>\n",
       "      <td>2012-11-17 23:52:38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93821 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                          title  \\\n",
       "0          1  Not a watercolor book! Seems like copies imo.   \n",
       "0          1  Not a watercolor book! Seems like copies imo.   \n",
       "0          1  Not a watercolor book! Seems like copies imo.   \n",
       "0          1  Not a watercolor book! Seems like copies imo.   \n",
       "0          1  Not a watercolor book! Seems like copies imo.   \n",
       "...      ...                                            ...   \n",
       "9999       2                         Dr von Igelfeld afield   \n",
       "9999       2                         Dr von Igelfeld afield   \n",
       "9999       2                         Dr von Igelfeld afield   \n",
       "9999       2                         Dr von Igelfeld afield   \n",
       "9999       2                         Dr von Igelfeld afield   \n",
       "\n",
       "                                                   text  \\\n",
       "0     It is definitely not a watercolor book.  The p...   \n",
       "0     It is definitely not a watercolor book.  The p...   \n",
       "0     It is definitely not a watercolor book.  The p...   \n",
       "0     It is definitely not a watercolor book.  The p...   \n",
       "0     It is definitely not a watercolor book.  The p...   \n",
       "...                                                 ...   \n",
       "9999  Professor Dr Moritz-Maria von Igelfeld leaves ...   \n",
       "9999  Professor Dr Moritz-Maria von Igelfeld leaves ...   \n",
       "9999  Professor Dr Moritz-Maria von Igelfeld leaves ...   \n",
       "9999  Professor Dr Moritz-Maria von Igelfeld leaves ...   \n",
       "9999  Professor Dr Moritz-Maria von Igelfeld leaves ...   \n",
       "\n",
       "                                                 images        asin  \\\n",
       "0     [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB   \n",
       "0     [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB   \n",
       "0     [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB   \n",
       "0     [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB   \n",
       "0     [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB   \n",
       "...                                                 ...         ...   \n",
       "9999                                                 []  1400095093   \n",
       "9999                                                 []  1400095093   \n",
       "9999                                                 []  1400095093   \n",
       "9999                                                 []  1400095093   \n",
       "9999                                                 []  1400095093   \n",
       "\n",
       "     parent_asin                       user_id               timestamp  \\\n",
       "0     B09BGPFTDB  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485   \n",
       "0     B09BGPFTDB  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485   \n",
       "0     B09BGPFTDB  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485   \n",
       "0     B09BGPFTDB  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485   \n",
       "0     B09BGPFTDB  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485   \n",
       "...          ...                           ...                     ...   \n",
       "9999  1400095093  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-11-17 23:52:38.000   \n",
       "9999  1400095093  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-11-17 23:52:38.000   \n",
       "9999  1400095093  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-11-17 23:52:38.000   \n",
       "9999  1400095093  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-11-17 23:52:38.000   \n",
       "9999  1400095093  AHXWUCTMVBQXDVMDFPA3NO43QF2Q 2012-11-17 23:52:38.000   \n",
       "\n",
       "      helpful_vote  verified_purchase sentiment  \\\n",
       "0                0               True  negative   \n",
       "0                0               True  negative   \n",
       "0                0               True  negative   \n",
       "0                0               True  negative   \n",
       "0                0               True  negative   \n",
       "...            ...                ...       ...   \n",
       "9999             0              False  negative   \n",
       "9999             0              False  negative   \n",
       "9999             0              False  negative   \n",
       "9999             0              False  negative   \n",
       "9999             0              False  negative   \n",
       "\n",
       "                                             text_array  \n",
       "0                It is definitely not a watercolor book  \n",
       "0                           The paper bucked completely  \n",
       "0       The pages honestly appear to be photo copies...  \n",
       "0      I say that bc if you look at the seal pics yo...  \n",
       "0       As someone who has made many photocopies of ...  \n",
       "...                                                 ...  \n",
       "9999  <br /><br />Fans of McCall Smith's other serie...  \n",
       "9999    Dr von Igelfeld is not as nearly sympathetic...  \n",
       "9999    Dr von Igelfeld's exploits lean more towards...  \n",
       "9999    Unlike the other series I am not particularl...  \n",
       "9999                                                     \n",
       "\n",
       "[93821 rows x 12 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.explode(column='text_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8698618",
   "metadata": {},
   "source": [
    "### SPLIT SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7956955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Function to split text into sentences safely\n",
    "def split_into_sentences(text):\n",
    "    try:\n",
    "        return nltk.sent_tokenize(text)\n",
    "    except:\n",
    "        return [text]  # fallback if text is invalid\n",
    "\n",
    "# Apply sentence splitting\n",
    "df[\"sentences\"] = df[\"text\"].apply(split_into_sentences)\n",
    "\n",
    "# Each sentence gets the same sentiment as the review\n",
    "df = df.explode(\"sentences\").rename(columns={\"sentences\": \"sentence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bdf29b",
   "metadata": {},
   "source": [
    "### TEXT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181fb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                                     # lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)              # remove URLs\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)                   # remove mentions/hashtags\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)                         # remove numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()                # normalize whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "388da0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"sentence\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3025306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  it is definitely not a watercolor book\n",
       "0                             the paper bucked completely\n",
       "0       the pages honestly appear to be photo copies o...\n",
       "0       i say that bc if you look at the seal pics you...\n",
       "0       as someone who has made many photocopies of pa...\n",
       "                              ...                        \n",
       "9999    this short volume like the rest of this series...\n",
       "9999    it is not necessary to read the earlier novels...\n",
       "9999    dr von igelfeld is not as nearly sympathetic a...\n",
       "9999    dr von igelfelds exploits lean more towards th...\n",
       "9999    unlike the other series i am not particularly ...\n",
       "Name: clean_text, Length: 68881, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e4d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b8c8c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definitely', 'watercolor', 'book']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenizer(df['clean_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d7e365d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'buck', 'completely']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenizer(df['clean_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6bd4acef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [t for t in tokens if t not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b8532d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['it is definitely not a watercolor book',\n",
       "       'the paper bucked completely',\n",
       "       'the pages honestly appear to be photo copies of other pictures',\n",
       "       ...,\n",
       "       'dr von igelfeld is not as nearly sympathetic a character as others of mccall smiths nor is there an ongoing story being told',\n",
       "       'dr von igelfelds exploits lean more towards the absurd than the other series',\n",
       "       'unlike the other series i am not particularly anxious to read the next book in this series'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d4d49d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f416449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text_lemm'] = lemmatize_tokens(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7dc8cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it is definitely not a watercolor book',\n",
       " 'the paper bucked completely',\n",
       " 'the pages honestly appear to be photo copies of other pictures',\n",
       " 'i say that bc if you look at the seal pics you can see the tell tale line at the bottom of the page',\n",
       " 'as someone who has made many photocopies of pages in my time so i could try out different colors mediums that black line is a dead giveaway to me',\n",
       " 'it’s on other pages too',\n",
       " 'the entire book just seems off',\n",
       " 'nothing is sharp clear',\n",
       " 'there is what looks like toner dust on all the pages making them look muddy',\n",
       " 'there are no sharp lines there is no clear definition',\n",
       " 'at least there isn’t in my copy',\n",
       " 'and the coloring book for adult on the bottom of the front cover annoys me',\n",
       " 'why is it singular not plural',\n",
       " 'they usually say coloring book for kids or coloring book for kids adults or coloring book for adults plural',\n",
       " 'lol plus it would work for kids if you can get over the grey scale nature of it',\n",
       " 'personally i’m not going to waste expensive pens paints trying to paint over the grey black mess',\n",
       " 'i grew up in sw florida minutes from the beaches i was really excited about the sea life in this',\n",
       " 'i hope the printers designers figure out how to clean up the mess bc some of the designs are really cute',\n",
       " 'they just aren’t worth my time to hand trace transfer them but i’m sure there are ppl that will be up to the challenge',\n",
       " 'this is one is a hard no',\n",
       " 'going back',\n",
       " 'i tried',\n",
       " 'missing the sketch pad',\n",
       " 'even worse i realized it’s identical to the drawing lab for mixed media artists book i already bought',\n",
       " 'every page has a crease running the entire length of the book about an inch and a half from the edges',\n",
       " 'only read and believe things you want to see come true',\n",
       " 'focus your attention on stories that uplift and inspire a greater future',\n",
       " 'the author meant well but has his own journey and beliefs to conquer to see clearly',\n",
       " 'my little one just likes doctors so i thought this book would be fun but it’s not what i expected',\n",
       " 'it’s more about helping if your little one is scared of going to the doctor',\n",
       " 'there is only one picture of the doctor in the book',\n",
       " 'nothing new for a collector of antique jewellery',\n",
       " 'pretty much all the pieces on this book have been in other jewelry books',\n",
       " 'and the funnyannoying thing no prices of the auction prices are listed eitherbr br sad to say i was really disappointed with it',\n",
       " 'buy a used copy if you really want it',\n",
       " 'this is not what i thought it was',\n",
       " 'all of the questions are way too close together the book is not meant to be written in',\n",
       " 'i wanted a book my loved ones could fill out the answers to the questions in',\n",
       " 'this is just a huge list of questions',\n",
       " 'way more questions than anyone would ever want to answer',\n",
       " 'i got the book but cd is missing',\n",
       " '',\n",
       " '',\n",
       " 'this book is dumb maybe worth certainly not you could easily find this in a dollar store and prob even better there are cupcake pictures and a few stickers not sure what i was expecting but this was definitely a disappointment',\n",
       " 'hard to get through was very disappointed with this book it was as if it was written by a fan with a crush on anita',\n",
       " 'buyer beware',\n",
       " 'i guess i thought at this would be a regular size book',\n",
       " 'of course shame on me for not looking at the dimensions',\n",
       " 'this is a small almost pocket sized book with limited information in it pages are small with large type most with black and white pics',\n",
       " 'i never would have purchased this had i paid attention to the specifications',\n",
       " 'i would return it but i used it in my for package and if i returned it i would lose out',\n",
       " 'disappointing terrible purchase',\n",
       " 'i ordered this stamping book as usedcondition good',\n",
       " 'sadly nothing about it was good',\n",
       " 'thirty pages has what appeared was mold and mildew but the worst part was the last section of the book the pages and cover completely stuck together',\n",
       " 'it looks like the book was left in the rain and got saturated and left to dry because you couldn’t even pry the pages apart',\n",
       " 'it was totally worthless',\n",
       " 'sad very sad',\n",
       " 'not what i thought',\n",
       " 'what a huge disappointment',\n",
       " 'they have three basic sweet cream bases best good last resort as they describe them',\n",
       " 'sounds reasonable right',\n",
       " 'except that for their best version they omitted the cooking directions',\n",
       " 'seriously',\n",
       " 'so just google a good ice cream base recipe',\n",
       " 'they go on to provide some of their most popular flavors but honestly you need to be able to guess about their cooking process',\n",
       " 'i am less than impressed',\n",
       " 'the first or so pages are all about them and some ho hum info about ingredients',\n",
       " 'i would definitely pass on this purchasebr update after some research i have discovered that is book is really old and before the time of the importance of cooking raw eggs',\n",
       " 'really',\n",
       " 'my grandma taught me that about years ago long before ben or jerry thought about writing a worthless ice cream recipe book',\n",
       " 'doesnt change the fact that this book is junk',\n",
       " 'save your money',\n",
       " 'its easy enough to find a safe recipe cooked or not online',\n",
       " 'the pages are copied from an original ’s book which were then recopied and well several pages were just black and others blurred',\n",
       " 'my interest is mostly on deep and reinforcement learning so the review is more pertinent to step',\n",
       " 'i hate the textbook or technical book which introduce something without proper context notation explanation',\n",
       " 'you dont have to explain everything and cover every base it is a fast moving area',\n",
       " 'but you do you need to be thorough andor selfcontained',\n",
       " 'this chapter of the book is pretty much a pile of code and with lightly sprinkled narrative which really teach you nothing',\n",
       " 'for beginners looking to learn you can pretty much forget about it',\n",
       " 'these were wet and smelly with some type of chemical',\n",
       " 'they were in individual plastic bags which were sealed',\n",
       " 'the pillow cases were actually wet inside the packages and had a chemical odor',\n",
       " 'the outside packaging was drybr i washed them by hand times and each time the water was full of dye',\n",
       " 'ive soaked them in vinegar and letting them air dry outsidebr even if they are alright now id never use them indoors due to the unknown chemicalbr good chance ill be returning these',\n",
       " 'i didnt like the meanness and name calling in part of the storybr my grandson knows not to bully and make people feel bad',\n",
       " 'at one point in the book the giraffe says i am useless after being called a fool clumsy and weirdbr my grandson doesnt need a book that makes bullying appear acceptable',\n",
       " 'poorly written and hard to place a timeline as the author rambles in and out of accounts of incidence',\n",
       " 'she writes as shes thinking diiferent thoughts that come into her mind',\n",
       " 'i had no patience to read this and decided to watch her youtube video',\n",
       " 'not much betteri gave up on this too',\n",
       " 'seems to make a good point if she can ever get to it',\n",
       " 'worst woods book ive read',\n",
       " 'and i have read them all',\n",
       " 'i dont believe the stuart woods wrote it',\n",
       " 'the politics part ruined it as well as the style',\n",
       " 'ill have to get over this before buying another',\n",
       " 'tastelessmore like a cracker then a cookie',\n",
       " '',\n",
       " 'strange and a bit disturbing',\n",
       " 'this book wasn’t anything i thought it would be after reading the reviews absolutely ridiculous worse than any soap opera ever',\n",
       " 'don’t waste your time or money',\n",
       " 'i just finished this book and was sorely disappointed i had such high hopes',\n",
       " 'the story telling was mediocre at best expending far too much focus on highly repetitive intervals looking at dating websites casual sex with strangers gossiping about these two things to friends constantly even when it means losing her work and home all she cares about are the men',\n",
       " 'then there is a rush at the very last leg of the book to tie everything up in a very forced and very happy ending which makes absolutely no sense if you actually read the entire story',\n",
       " 'worse there is so much racism in this book and its not coming from the white folk as it is set up to appear but from the main character and her tiny circle of friendsbr br spoiler warningbr our main character mc is apparently one of only five black people in all of london',\n",
       " 'black people are so scarce in london that anywhere our mc goes everyone is riled up at her presence even when she is doing nothing',\n",
       " 'everyone has an extreme reaction to the mc of which she and her friends constantly mock white people for',\n",
       " 'yes this book abuses the trope that white people are evil and racist and only out to fetishize black women over and over and over againbr br the mcs entire preoccupation spans three months of casual sex with over random strangers while her real relationship is on pause for days where she was supposed to work on herself to be a better emotional partner',\n",
       " 'of this book is the mc looking at dating apps while yearning for her white boyfriend and hooking up with whomever will give her time',\n",
       " 'and then she goes back to her friends and they make fun of the white peoples reaction to this and the white peoples reaction to thatbr br we watch her bounce to and from the gynecologists office where she keeps getting std and pregnancy tests due to all the unprotected promiscuity and the mcs decline psychologically as she develops panic attacks',\n",
       " 'we watch her fail at just about every relationship in her life but she doesnt ever see it that way',\n",
       " 'we watch her struggle but never grow never learn from her mistakes never become a better person than she was at the beginning of the book',\n",
       " 'she has no interests no hobbies and no drive beyond how much censored she can get',\n",
       " 'its actually unsettling how flat and one dimensional the mc is she literally has no will to live beyond men and their genitalsbr br this book is trying to send a message and it fails miserably',\n",
       " 'mc sets up situations time and again with people and then claims she is a victim of racism',\n",
       " 'she repeatedly complains about being fetishized throughout the entire book but every situation with a man she is all about the sex and letting them do whatever they like to her even if it degrades her',\n",
       " 'the irony is that she almost exclusively selects white men as her partners and refuses to get with a black man at allbr br the author even managed to work the black lives matter catalyst and movement into the story but all it was used for was a mini argument between the mc and one of her many one night stands and never again mentioned instead of using it to send out a powerful message such as the march scene suggested it might be',\n",
       " 'i would say if anything this book is an illustration of what is exactly wrong with trying to counter racism with further racism',\n",
       " 'maybe just stop as a whole',\n",
       " 'i breezed through this book really fast more than k words per hourbr br i had hoped this was more of an educational book but it really isnt',\n",
       " 'its on of those this is what i did with a lot of repetition of what the author did which begins to feel like filler rather than explanation while only superficially detailing suggested steps none of which explain how to type faster while writing a bookbr br the author probably achieved his goal of making his book a best seller with the promises on the cover of being able to teach any reader how to write k words per hour but there is nothing to substantiate these claims',\n",
       " 'its very much along the lines of some new herbal dietary shake it can advertise itself as it likes the fda still wont approve it or take its unbelievable claims as legitimatebr br but that doesnt matter to the author hes already told you this from the beginning',\n",
       " 'this is a person who outsources his book ideas to other writers pays them for their labor and puts his name on the book',\n",
       " 'in fact the first few chapters covers the fact that the author is only in this for the prestige and financial gain of writing hasty books on popular subjects even if he knows absolutely nothing about them or tried it himself',\n",
       " 'its a con job and openly admittedbr br therefore this book is not a selfhelp for writers it doesnt teach you how to organize your writing work and it definitely does not help you achieve k words per hour',\n",
       " 'its a long soliloquy often redundant on how a procrastinator managed to write a book himself for a change and because relying on other people todo his work for him fell through he pushed himself like crazy to meet a deadline',\n",
       " 'that is all it isbr br now the only part i found slightly informative is how to trick amazon into listing you as a bestselling author another con in a way even if your book is crud',\n",
       " 'it has nothing to do with your book its subject or quality its about trickery',\n",
       " 'and makes sense because every other author i meet who market on amazon is a bestselling writer even if they can barely sell their book after its initial releasebr br save your money',\n",
       " 'there really is nothing being taught here beyond conning your way through the writing industry writing about topics you know nothing about just to bank on popular trends and making promises which do not deliver',\n",
       " 'the premise was very good and that is the only reason i made it to before quitting in frustration',\n",
       " 'the writing was very stunted',\n",
       " 'think high school creative writing class',\n",
       " 'i wanted to finish but it was that bad',\n",
       " 'if the author were to get an editor or a ghost writer',\n",
       " 'i would try again',\n",
       " 'a little disappointing but thank goodness for kindle unlimited',\n",
       " 'i ordered the quotegypt gamequot waay back in grade or so and have read it a million times',\n",
       " 'i loved the character development the sneaking around aprils melodramatic flares and the rituals of the egypt gamebr two days ago i found out that zilpha keatley snyder had written quotgypsy gamequot as a sequel',\n",
       " 'i read the amazoncom reviews and was surprised to see that it received such poor ratings',\n",
       " 'however based on my love for quotthe egypt gamequot and my love of roma gypsy culture i bought it and have just finished it',\n",
       " 'here is my verdictbr i liked the fact that toby was part gypsy and had a shawl and jewellery that his rom grandmother had left him plus the fact that tobys dad chipped in and provided a caravanbr i also liked how april and melanie started practicing palmistry and showed some enthusiasmthat seemed more like the old gang',\n",
       " 'a major disappointment was that the plot really had nothing to do with the gypsy game although it was a decent mystery by itselfbr the character development is sadly lacking and april doesnt seem like the same person at all',\n",
       " 'all she seems to do is fight with melanie and everyone else sits around arguing',\n",
       " 'no one can agree and the game is never played',\n",
       " 'toby as the protagonist is a fresh new voice but not enough to successfully keep the readers attention for pagesbr i could definitely feel both the changed writing style and the year gap between the booksit felt like the s even though the story was supposed to take place directly after the egypt gamebr the book was extremely depressing the story of tobys mom the persecution of the gypsies in europe tobys hunger and loneliness and the plight of the homeless garbo vince and mickey',\n",
       " 'the first two chapters made it seem like the gypsy game would once again be magical but the magic quickly disappearedbr i wont say that this book is a complete waste of time but it does seem to drag on dwell on dark subjects and is lacking all the mystery and excitement of the egypt game',\n",
       " 'it is a decent mystery on its own but i was expecting a sequel that followed the lines of the original especially with a title as promising as quotthe gypsy gamequot',\n",
       " 'the book i was sent is missing pages',\n",
       " 'a mistake',\n",
       " 'buy from your school and avoid the bs',\n",
       " 'the book is just a listing of brand specific drinks which makes looking for drinks to make a pain in the butt if you are making them at home or dont work at a really and i mean really fancy bar',\n",
       " 'it asks for many uncommon drink ingredients and the layout is laborious to navigate',\n",
       " 'they also dont have any of the fun drinks people are ordering now a days sour patch kids payday bar birthday cake',\n",
       " 'this is a book for the rich and the traditional in pallet',\n",
       " 'if you want a fun listing of drinks to make look elsewhere',\n",
       " 'bad art',\n",
       " 'dont know who university press is but they should be ashamed of themselves',\n",
       " 'this is more like a glorified pamphlet than a book',\n",
       " 'about pages of largeprint type will read it but am disgusted that i bought it and will consider it a lesson learned the hard way',\n",
       " 'maybe im a prude if such a person exists anymore but i was disappointed and surprised to find the fword on page five',\n",
       " 'i decided its not worth my time to read any further so ill either donate it or more likely throw it away',\n",
       " 'im just glad i didnt waste any more time on it than that',\n",
       " 'i gave up on this after about pages in which the author said nothing much and she said it over and over again',\n",
       " 'i dont like to be critical but i also dont like to waste money and thats what i did',\n",
       " 'its going to the thrift store in a few days',\n",
       " 'sorry',\n",
       " 'i give this book one star because i cant give less',\n",
       " 'this book has poorly written instructions and the projects are copies of other peoples designs mostly from the s and s',\n",
       " 'taking someone elses design changing the name of the design and calling it yours doesnt make it yours and this is what jill wiseman should be famous for',\n",
       " 'she is not a designer and this poorly written instruction book testifies to this fact',\n",
       " 'an absolute waste of money',\n",
       " 'dont even bother trying to read this garbage',\n",
       " 'garbage',\n",
       " 'absolute crock of nonsense',\n",
       " 'a little too vague good enough for quick review but not specific enough to study',\n",
       " 'returnedbr purchased a new textbook it arrived without the plastic wrap and mymath lab code has been removed',\n",
       " 'defeats the purpose of purchasing a new expensive textbook',\n",
       " 'this felt a little cultlike',\n",
       " 'pizzabr gate muchbr so now we’re teaching children to keep secrets from their parents for a secret pizza party',\n",
       " 'i bought this to educate my child about pedophilia and grooming as well as my family and friendsbr br',\n",
       " 'dont buy',\n",
       " 'the heading says the calendar is x whereas the fine print gives the real size of x',\n",
       " 'it also describes it as large which it clearly is not',\n",
       " 'ive never seen a wall calendar this smallbr on top of this when a calendar has a title on the front such as dogs you expect to see a different photo of a dog on each page not one dog and the rest all different kinds of animals',\n",
       " 'thats what this calendar has',\n",
       " 'one photo of hampton court palace and the rest pictures of other places',\n",
       " 'one page has a picture of palm trees one page has a pagoda and a barge',\n",
       " 'and even more ridiculous none of the pictures are labeled so you have no idea where it is or what it is a picture of got as a gift going in the trash',\n",
       " 'boring and long',\n",
       " 'the plot is hard to follow at times',\n",
       " 'there were no main characters that i could cheer for',\n",
       " 'the main character is a drunk and a drug addict',\n",
       " 'not worth the time to read',\n",
       " 'jmo',\n",
       " 'sadly retuned this book even though the prince is one of my top reads',\n",
       " 'i really wanted a nice unique copy for my bookshelf but unfortunately i just hated the plastic sticky feel of the cover and the cheap paper that it was printed on',\n",
       " 'very disappointed',\n",
       " 'this book was nothing special to the yorkshire terrier breed',\n",
       " 'it has the same information in it that you could have read in a generic dog owner manual',\n",
       " 'really disappointed so returned',\n",
       " 'i couldnt even get past the sample chapters desperate fbi agent falling all over her target',\n",
       " 'the story was so slow i quit and didnt even purchase to finish not worth it he time',\n",
       " 'their super bowl wins against the new england were pure luck no skill',\n",
       " 'i loved the movie but hate the book',\n",
       " 'the book is nothing more than the twisted writing of a man with deep sexual perversion issues',\n",
       " 'im sure glad the movie didnt go down this dark alley',\n",
       " 'how novel',\n",
       " 'female cop with father who dosent praise her fights male doper serial killer',\n",
       " 'gratuitious violence',\n",
       " 'save your money folks',\n",
       " 'nothing new here',\n",
       " 'i always look up more about people who are subjects of historical fiction to get the real info on someone',\n",
       " 'this time i did it halfway through the book which i chose not to finish because it is way more fiction than historical when it comes to the person it is about',\n",
       " 'the setting and period information was well researched but the story was embellished to the point that it should not be allowed to stand unchallenged',\n",
       " 'last year i read the great mistake by jonathan lee an excellent and true to the facts historical fiction piece about andrew haswell green known as the father of new york for his incredible accomplishments relating to the creation of central park the ny public library making the five boroughs one city and more',\n",
       " 'his death was bizarre in that he was shot by a cornelius williams a black man who mistook him for the very wealthy john pratt',\n",
       " 'the great mrs elias opens with this murder because the murderer accused green who he thought was pratt of keeping bessie davis from him',\n",
       " 'bessie davis a black woman born into poverty in philadelphia was now a very wealthy brothel owner with a home on central park west',\n",
       " 'john pratt was extremely involved with hannah elias loaning her money and giving her money for her businesses and real estate',\n",
       " 'i assume the book is about to turn to the blackmail case his kids made him bring against hannah',\n",
       " 'just read newspaperscom about this or wikipedia',\n",
       " 'its way more interesting than this overly long and overly fictionalized version of hannah eliass life to the extent i could stand to listen to itbr br i just turned off the audible version of it',\n",
       " 'i do not like the narrator her phrasing or her intonations',\n",
       " 'i know because i read a book that stayed true to the eliasdavis story that there are so many liberties taken with her life that it is wrong to call it historical fiction',\n",
       " 'i want to know that the facts in a historical fiction novel are not so far off that if i say something about an event or person in history im not falsifying things',\n",
       " 'and this book is way too long',\n",
       " 'the stuff that is accurate is the stuff that sound boring against the authors imaginary relationships and events she used to fill things in',\n",
       " 'its all about her learning about how to invest money and accumulate wealth',\n",
       " 'and sure a sex workers life is going to be salacious but so much is thrown into this book gratuitously like a lovehate relationship with a famous black inventor who she probably never met',\n",
       " 'i cant tell you if id have liked this a little better if i hadnt already read an accurate depiction of hannah elias in mr lees book followed by reading newspaper articles of the day because it was all so interesting',\n",
       " 'nothing could make me listen to this for another seven hours when there are so many good books out there begging to be read',\n",
       " 'just',\n",
       " 'no',\n",
       " 'im not angry youre angry',\n",
       " 'i compare this pundit and her followers to what peta members are to the left pure stupidity and mindless forcing of unproved beliefs upon others who have already learned that one can pick and choose their poltical beliefs based on informed decision makingbr br if you like to pidgeonhole yourself as a conservative and need idiotic statistics with little fact behind them to validate your existance then by all means buy and try to read this book',\n",
       " 'this book replaces intelligent rational conservatives withwhich one right or leftminded can actually discuss things with idiotic dittohead morons who spit out the rehashed opinions of such purile pundits',\n",
       " 'i call it nascarification of the rightbr br on the flipside the text is actually small print unlike bill oswhich i believe is meant for yearolds',\n",
       " 'arrangements too convoluted sounds nothing like the originals',\n",
       " 'easier than other level s i own',\n",
       " 'too small print to read even with reading glasses',\n",
       " 'why would anyone take the opinions or facts of a selfconfessed sexual predator seriously',\n",
       " 'mr kratz is on a mission towhat exactly',\n",
       " 'the book is about himself',\n",
       " 'not steven avery and not teresa halbach',\n",
       " 'not sure what hes trying to accomplish here',\n",
       " 'hes hostile and abrasive',\n",
       " 'also a predator',\n",
       " 'how is this man not in jail',\n",
       " 'book is great step by step but refers to enclosed cd with examples and software',\n",
       " 'the cd is no longer available so book is worthless',\n",
       " 'wow',\n",
       " 'this was listed as a used book but it should have said this was a crumpled very dirty pages ripped out book',\n",
       " 'looks like it was run over by a car or several trucks',\n",
       " 'and i am not a picky buyer',\n",
       " 'the writing is trite and completely putdownable',\n",
       " 'i dont understand the popularity of this series',\n",
       " 'i found the writing to be chopped up and very predictable',\n",
       " 'stopped wasting my time after or so pages there are too many other good books out there to read',\n",
       " 'maybe it is meant for the tween audience',\n",
       " 'wasnt impressed at all maybe or recipes i will use',\n",
       " 'the book is too small',\n",
       " 'difficult to read',\n",
       " 'waste of my money',\n",
       " 'to be honest with you i will not go through the aggravation through changing this with amazon but i am hispanic when am i going to cook anything from here got the wrong impression of the book its not for me so it will sit their in my treasure box for christmas gifts thank you',\n",
       " 'the only reason i continued to read past the first few chapters was because larry mcmurtry wrote it',\n",
       " 'i finally gave up halfway through deciding it wasnt going to get any better',\n",
       " 'im just glad i borrowed it from the library and didnt pay good money for it',\n",
       " 'another white liberal female university department chair trying to woke her way up to a deans position',\n",
       " 'you dont have to read past the first chapter to see that this is a sophomoric attempt to besmirch anything male or white',\n",
       " 'never mind that her premises are factually incorrect',\n",
       " 'consider yearold kyle rittenhouse who used his semiautomatic weapon to kill two black men in kenosha wisconsin while waging a glorious race war on behalf of his inherited white power',\n",
       " 'im surprised national geographic sponsors such drivel',\n",
       " 'really makes you wonder how much of the rest of the book is bs',\n",
       " 'this passes as academia nowadays',\n",
       " 'its been over a month and im still waiting on my book',\n",
       " 'ive received two emails apologizing and blaming homeland security and postal delays',\n",
       " 'careful this is not the actual book— just discussion prompts',\n",
       " 'you’d think otherwise at a glance',\n",
       " 'it’s not even worth the hassle to return this book as the fee through ups is half the price of the book',\n",
       " 'i am appalled by this book and by the authors stance towards the children he taught',\n",
       " 'this is a book filled with his own failure which he turns into loathing of poor black and brown kids',\n",
       " 'most teachers have been in a tough position at some point',\n",
       " 'and the good ones find a way to master their own sense of balance their craft and to structure a class and day that inspires kids to do better',\n",
       " 'the portraits he paints of his students are caricatures of the ugliest kind',\n",
       " 'worst he fails to realize that fear and loathing will never bring kids around only love will',\n",
       " 'even more enraging he uses his time with them to make more money',\n",
       " 'i disliked the situations the writer presented',\n",
       " 'however they are parts of real life i dont think sexual abuse bigomy drug abuse child abuse',\n",
       " 'these issues in my opinion are too much for this age group',\n",
       " 'way too complicated for me',\n",
       " 'there is no real step by step',\n",
       " 'i think this is geared more for someone who already knows how to weave but wants a small one that can travel with them',\n",
       " 'sadly my brain just cant process her way of teaching',\n",
       " 'the book is detailed enough but i was hoping for some inspiring artistic work to get me motivated',\n",
       " 'i didnt find it in this book',\n",
       " 'this is a horrible page brochure book stapled together on rug hooking',\n",
       " 'he doesnt really tell you how to rug hook',\n",
       " 'but he goes into great boring detail about what you use in the event you can figure out how to do it',\n",
       " 'i think kevins wife must hook rugs and he has been watching her do it for so long he figured he could write a book about it',\n",
       " 'never got it',\n",
       " 'shes come undone is my favorite book of all time but lambs other novels have never stacked up',\n",
       " 'this is by far the worse',\n",
       " 'i was so bored i didnt finish',\n",
       " 'admissions is spelled wrong on the cover',\n",
       " 'does not bode well for gifted learning',\n",
       " 'im sorry i feel stupid because everyone on the end pages went on and on about the amazing writing and how good a book this is but i just absolutely did not get it and would not recommend it',\n",
       " 'too long too dark and i think probably trying to do too much',\n",
       " 'i didnt like any of the characters i didnt like the story i didnt like the plot i didnt like much of anything except the idea of what i think he was trying to do and i hope he did and apparently he did for many people but not for me',\n",
       " 'im glad other people like this book but i seriously thought it was the worst thing ive read in a very long time',\n",
       " 'it took an excellent idea and made it into this long tedious whiney fat girl soap opera angst ridden crap fest',\n",
       " 'i almost stopped reading the book several times but i believe in giving an author every chance to redeem him or herself',\n",
       " 'this author did not',\n",
       " 'if youre looking for a soap opera this is good stuff for you',\n",
       " 'ive youre looking for a science fiction modern novel about the possibilities of the future and the unknown worlds of the dead this is absolutely a huge waste of your time and money',\n",
       " 'sorry but this book just heaves',\n",
       " 'i would literally take it from a friends hand in a bookstore and refuse to let him buy it its that bad',\n",
       " 'do not waste your time',\n",
       " 'there are so many good books out there and its a shame when a piece of work like this one actually gets good reviews',\n",
       " 'im so disappointed in this cookbookbr i have to say i bought it at costco when it first came out and did not have time to look at it or use it right awaybr and its so old school type of cookingbr br im wanted a cookbook with healthy food recipes not a cookbook using processed canned foods and that is what this isbr br i gave it away to a friend that does care what she eats and is not well but she like this cookbook',\n",
       " '',\n",
       " 'choose this rating according to what i like to read',\n",
       " 'that gives people drawn to this to set there own standards',\n",
       " 'it just was not my cup of tea and i dont think i will follow this author any time soonthis',\n",
       " 'a very basic book not a lot of variety in design techniques',\n",
       " 'it was not new either it had a library envelope in it probably very overdue',\n",
       " 'i have not finished reading the book but i have not been impressed from what i have read so far',\n",
       " 'most of the content in this book can be found on the internet',\n",
       " 'the plot of the chill a novel sounds promisingit’s about a huge reservoir that is haunted by the remnants of galesburg a community that was drowned when the reservoir’s dam was built to deliver water to downstate new york',\n",
       " 'unfortunately the novel is almost unreadable',\n",
       " 'whatever story exists is buried under the sheer weight of words expended to establish an ominous atmosphere by describing minute details of a dilapidated cabin underground nyc sewers the reservoir’s cold currents etcbr br by the end of part one about of pages almost nothing has happened',\n",
       " 'a grandmother who once lived in galesburg “goes home” by drowning herself in the reservoir using weighted and padlocked chains',\n",
       " 'a new york city sewer worker starts seeing galesburgrelated hallucinations in the nearly complete water tunnel he is building',\n",
       " 'a local sheriff kicks his drugaddicted son out of his home telling the son he is no longer fit enough to swim the reservoir',\n",
       " 'the son goes swimming in the reservoir and hallucinates killing a dam inspector who has just discovered a condition that will lead to the dam’s failure',\n",
       " 'the sewer worker’s daughter and granddaughter of the drowned grandmother arrives to investigate the son’s story and realizes something is horribly wrong when the son mentions the name of a photographer who might have witnessed the killingbr br at this point i gave up',\n",
       " 'it’s clear that something very bad is going to happen at the reservoir but i don’t care',\n",
       " 'the characters aren’t memorable or well developed and the puzzle of how galesburg is going to get its revenge is only mildly interesting',\n",
       " 'i certainly don’t want to read another pages of overly descriptive prose to find out what happens next in the very thin overall story',\n",
       " 'the missing corpse a brittany mystery lost me after only pages as those were mostly filled with factfilled passages about zoo penguin behavior the dying out of the lighthouse keeper’s profession the varieties of rain in brittany the emergence of life from brittany’s seawater the geography of the plateau between the estuaries of the mythical aven and belon rivers and the worldwide problem of sand theft from beaches',\n",
       " 'all these boring minilectures are out of place in mysterythriller escape fictionbr br it is true that a probable murder turns up on page but when the main character commissaire dupin reaches the scene there is no body no blood and no disturbance of the soil',\n",
       " 'worse yet the person who reported seeing the body is an elderly eccentric former actress sophie bandol who “gets confused sometimes”',\n",
       " 'so it appears that there is no murder after allbr br well thanks to the book’s title we know that old sophie wasn’t confused',\n",
       " 'however the murder setupa pristine crime scene with a missing body and detectives standing around wondering what to dodoesn’t grab me in the slightest',\n",
       " 'it isn’t interesting enough to make me want to slog through more descriptions of penguins sand theft and local scenerybr br commissaire dupin himself is boring because he’s depicted as deeply dissatisfied with a recent promotion that requires him to attend seminars on topics such as “conducting systematic and systemic conversations in investigative situations”',\n",
       " 'the fact that dupin grasps at any excuse for skipping out on the training programs doesn’t save himbr br the translation of the novel seems particularly uninspired',\n",
       " 'true francophiles may enjoy the book but the characters and local settings aren’t nearly as interesting as the ones in martin walker’s “bruno chief of police” series',\n",
       " 'when i order a book marketed as a mysterythriller i expect a relatively easytoread entertaining booka novel to be read for the story and then given away or recycled',\n",
       " 'what i do not want is a book with a plot that dribbles out information about what actually happened or is happening to the characters or that makes the reader’s job difficult by jumping around in timelines andor shifting abruptly from one firstperson viewpoint character to another',\n",
       " 'why should anyone bother to read a throwaway massmarket novel that transforms pleasurereading into a demanding jobbr br this is how it ends is one of the worst examples i’ve yet encountered of a massmarket “mysterythriller” that makes reading the story as difficult as possible for the unsuspecting readerpurchaser and delivers next to nothing as a reward for the readers effort in tracking the jumbledup eventsbr br this novel includes a couple of murders and two female angstridden firstperson narrators ella molly',\n",
       " 'perhaps the following partial list of early chapter titles will serve to alert casual mysterythriller readers as to what they are in for if they want to attempt this bookbr br ella nowth marchbr ella thenth marcheveningbr molly nowth marchbr ella thenth marchbr molly nowth marchbr ella then st marchbr molly nowth marchbr ella thenth februarybr br the chapters go on in the same fashion with skippingaround “then” dates for ella and forwardgoing “now” dates for mollybr br in my opinion a novel writer has utterly failed at hisher basic storytelling task when the reader must read the chapter labels to be able to tell which character is speaking and the times when the plot events are happening',\n",
       " 'exit strategy is full of brutality and torture',\n",
       " 'one main character jordan suffers so many knockout head butts you wonder how his skull let alone his brain manages to remain functional',\n",
       " 'there are also several extremely graphic descriptions of burned bloodied torturedtodeath or torturedandshottodeath bodiesbr br as for the story it jumps all over the place detailing with far too much detail the parallel events occurring in the lives of jordan his captors sam dennis jordan’s abandoned wife and children stephanie sophie haden his prekidnapping business partner alex and a detective who is trying to untangle the mess herron',\n",
       " 'there are even more characters but these are the most important',\n",
       " 'it doesn’t help that some of the characters are in different countriesbr br if that isnt confusing enough there is a private cipher that stephanie and jordan use for communication as well as an anagram that furthers the plot',\n",
       " 'there are kids’ emailtext messages thrown in for good measurebr br the plot itself is basically simple a debtridden ceo whose tech company is failing decides to call a number that will “disappear” him and set him up with a clean slate in a new life with a different identity',\n",
       " 'only he has immediate misgivings decides he wants to return to his old life is informed that he can’t and comes to suspect that someone else may have been behind everything that originally made him wish to disappearbr br the plot is slowmoving and the villain’s identity is guessable almost from the beginning definitely within the first pages',\n",
       " 'the characters aren’t particularly interesting and the ending isnt believable or satisfying',\n",
       " 'as previously mentioned the story regularly bogs down in too much detail regarding the ongoing lives of the many characters that the reader is supposed to track',\n",
       " 'the missing hours is a slowmoving confusing novel about kidnapandransom consultants experts who are hired to negotiate for the safe return of kidnap victims',\n",
       " 'it’s a hidetheball mystery told in chapters that shift viewpoint characters mostly alternating between sisterandbrother detectives leah and finn and timelines ongoing investigations and “disappearance” flashbacks',\n",
       " 'interspersed among the mysterythriller plot chapters are fictional “case histories” of kidnapping cases supposedly handled by the maincharacter consultants and fictional “published professional articles” about the samebr br i guess that the author knows a lot about reallife kidnapandransom negotiations and decided to educate readers about the field by incorporating her knowledge into a novel',\n",
       " 'however the case histories and articles don’t add to the plot and the rather unbelievable plot is thin boring and in its own way predictablebr br why anyone would choose to present a mysterythriller intended for a mass market audience in such a complicated format is beyond me',\n",
       " 'as for the kidnapandransomnegotiator content i prefer nonfiction when i need to be introduced to or educated about such a specialized topic',\n",
       " 'when i ordered first person a novel i thought that the bookpublishing aspect sounded interesting and that it was a mysterythriller',\n",
       " 'whatever book list i found it on it was badly misclassified because it appears to be a serious attempt at writing literaturebr br it’s a firstperson narrative written in long rambling sentences',\n",
       " 'there is minimal punctuationfor example conversations are reported on without all the bother of including quotation marks',\n",
       " 'the story is something about a ghost writer who’s failing at extracting information for an upcoming memoir from an infamous con man',\n",
       " 'in all honesty the book makes as much sense to me as james joyce’s asin ulysses',\n",
       " 'i cannot make head nor tail of itbr br neither the narrator nor the prose is interesting enough to justify the effort it would take for me to figure out this bookwhat it’s about or what the author’s intentions were in writing it',\n",
       " 'i leave this muchpraised novel to all the students of english literature who particularly enjoy reading “difficult” novels with expansive allencompassing literary themes',\n",
       " 'spoiler alert if i understand exhibit alexandra a novel at all it is a novel about a mentally ill performance artist alexandraamelia who transforms her own life into the ultimate performance art installation an installation that is intended to be exhibited in a new york art gallery',\n",
       " 'why anyone would be interested in viewing the resulting exhibition is beyond me but then ive never cared for or understood performance art anywaybr br this debut novel is told in firstperson narrative largely in flashbacks in alternating “now” and “then” chapters',\n",
       " 'sadly this seems to be the current fashion in debutnovelwriting',\n",
       " 'there is enough interior angst to fill a dozen novels',\n",
       " 'the angst is mostly in the form of the artist’s vicarious imaginings of how her abandoned husband and daughters are reacting and feeling after her disappearance and apparent murderbr br to the extent that this novel purports to examine the conflicts faced by an ambitious “career woman” who finds herself trapped in the role of “stayathome mother” it’s stale and trite',\n",
       " 'it really has nothing new to offer on the subject and the unlikeable “unreliable narrator” isn’t to be excused for escaping from suburbia in the extreme selfish and delusional manner that she chooses',\n",
       " 'her justifications at the end of the book fall totally flatbr br this novel is definitely not what one expects from a novel classified as a mysterythriller',\n",
       " 'it isn’t a thriller because there’s no excitement it isn’t a mystery because there’s a disappearance without a crime to be solved',\n",
       " 'maybe the novel is properly classified as “literary fiction” but however you classify it it’s a boring repetitive confusing novel that’s a total waste of the reader’s time',\n",
       " 'friend request is yet another novel about something terrible that happened when the main character was in high school that comes to light again years later that causes serious trauma or detriment to the adult character',\n",
       " 'in this example the main character louise did things that contributed to the death of a schoolmate maria some years earlier',\n",
       " 'louise is now a single working mother of a young son henry and she’s struggling to cope with daily life',\n",
       " 'what she doesn’t need is a facebook “friend request” from the longdead mariabr br the story is told in louise’s firstperson narrative mostly in chapters alternating between things as they are now and things as they were then',\n",
       " 'it’s all about teenage relationships cruel as only these can be and toxic adult relationships a high school reunion domestic violence',\n",
       " 'through it all louise comes across consistently as fearful ineffectual insecure and woefully eager to pleasebr br the plot moves slowly through flashbacks and when the mystery is finally revealed it isn’t very satisfying',\n",
       " 'the writing is okay but there are no likeable or particularly memorable characters',\n",
       " 'the basic idea what would you do if you received a “friend request” from a dead person is intriguing but the novel itself is extremely disappointing',\n",
       " 'the feed a novel is a slowmoving confusing postapocalypse survival novel',\n",
       " 'the apocalypse is the collapse of “the feed”a continuously streaming internetlike connection that communicates directly to people’s brains',\n",
       " 'it can be switched off but almost no one does it because it substitutes for speech in modern society',\n",
       " 'everything even ordering a meal in a restaurant is done by thought via the feedbr br then the president is assassinated live on the feed the feed goes down and society collapses',\n",
       " 'why this happens isn’t immediately explained',\n",
       " 'instead after the assassination is announced the reader is dropped into the world as it exists “six years later”',\n",
       " 'in this world the main characters are nearly starving and they’re struggling to eke out an agrarian existence along with a small group of friendly survivors',\n",
       " 'their difficulties are increased when their electrician expert is “taken”apparently by some mysterious remnant of the feed that grabs people’s mindsbr br you have to read and read and read to find out what’s happening in the “six years later” world',\n",
       " 'there are pages of conversations about what the survivors should do next and about what they can and can’t remember from their prefeedcollapse base of knowledge',\n",
       " 'everyone’s knowledge was ripped away by the collapse',\n",
       " 'the main characters leave the farm encounter the usual crazed competitorsurvivors in other locations form a new camp that is attacked discover that their daughter has disappeared and so onbr br information about what happened to the social structure and about what is controlling the remnants of that structure is parsimoniously dribbled out',\n",
       " 'the main characters are very ordinary people not particularly interestingthey just do what they must to survive including strangling anyone who is “taken”',\n",
       " 'following the convoluted story is made even harder by the long long chapters that are told from different characters’ viewpoints “tom” “kate” and that include the characters’ individualized flashbacks to the intervening years after the assassination',\n",
       " 'it takes a dedicated reader which i am not to slog through this mess of a novel',\n",
       " 'conversations with friends a novel is written in economical prosenot the kind that hemingway produced but the dull uninteresting kind',\n",
       " 'even worse the plot is all about slowdeveloping slowmoving relationships among characters that are neither memorable nor compelling',\n",
       " 'and of course as a debut novel it’s written with a firstperson narratorbr br i ordered this book because of the dublin setting which hardly matters and the advertised “best book” selections by vogue slate elle etc',\n",
       " 'i have no idea why this novel would make anyone’s “best book” list or why anyone would say that it doesn’t read like a debut novel',\n",
       " 'girls of paper and fire is a “jimmy patterson” book it’s one of james patterson’s line of books aimed at “young readers” meaning i guess “young adults”',\n",
       " 'it’s a fantasyromance novel obviously intended as the first entry in some sweeping saga see the cliffhanger in the epiloguebr br the fantasy setting is a world populated by three racescastes',\n",
       " 'pure humans are paper humananimaldemon mixtures are steel and pure demons are moon all of the castes are humanoid in form',\n",
       " 'paper is the lowest caste though there are “noble” families at the top of the castebr br the heroine is a paper girl with unusual golden eyes who is taken from her village located in a kingdom ruled by demons to become one of the demon king’s concubines',\n",
       " 'this is supposedly a high honor',\n",
       " 'she lives in the hidden palace but she’s still a concubine expected to yield to the demon kings physical demands',\n",
       " 'she’s also confined to the paper house portion of the palace grounds',\n",
       " 'she rebels against the demon king’s demands and falls in love with another paper girl a highborn onebr br personally i found the novel confusing what with all the strange rites and weird interactions between the human part demon and wholly demon characters',\n",
       " 'i also cannot see why young female readers should want to read about or identify with concubines even if they are rebellious concubines or concubines plotting their escapes',\n",
       " 'i seriously doubt that young male readers would be even remotely interested in this novel',\n",
       " 'br br if young women love this book then it’s fine with meit’s their choice',\n",
       " 'however i would never recommend it to anyone',\n",
       " 'in my opinion a fantasy novel needs to do more than establish a complicated fantasy kingdom to be worth reading',\n",
       " 'the devil’s wind a spider john mystery is a clumsilywritten novel about a reluctant pirate spider john',\n",
       " 'spider john is a ship’s carpenter who was forced into years of piratehood after the ship he was on was captured by piratesbr br in the novel spider john has barely escaped hanging in port royal jamaica',\n",
       " 'he is totally ashamed and appalled by his pirating career and wants nothing more than to sail home to england to his wife em as the ordinary nonpirate ship’s carpenter on the hms redemption get it',\n",
       " 'br br the novel pretty much lost me in the very first chapter when spider john and his sidekick hob are seen in a crowd and recognized as pirates',\n",
       " 'they get away by galloping off on two stolen horseseven though neither one knows how to stop a galloping horse',\n",
       " 'they dismount by simply jumping off and rolling into the weeds alongside the road losing their pursuers in the process',\n",
       " 'clearly the author knows nothing about horseback riding',\n",
       " 'br br as the novel continues spider john’s voyage home is complicated by the presence of sam smoke',\n",
       " 'as described by spider john’s incorrigible alsoformerpirate friend odin who also narrowly escaped hanging in jamaica sam smoke is an evil sadist the devil incarnate',\n",
       " 'odin treats john and the readers to a detailed account of sam’s torture and murder of a lazy sailor',\n",
       " 'naturally the voyage is further complicated later by the death of the captain which will result in formal inquiries when they reach portbr br the characters in this novel are cardboard caricatures of pirates',\n",
       " 'i kept expecting someone to say “avast ye swabs” or “aaaargh” or to appear with a parrot on the shoulder',\n",
       " 'i also did not appreciate the gratuitous torture scenes',\n",
       " 'the writing itself is clunky lacking flow in part because it keeps returning to john’s internal thoughts of hanging being recognized as a pirate and remorse',\n",
       " 'trial on mount koya a hiro hattori novel a shinobi mystery is the sixth “hiro hattori” mystery and it definitely does not work as a standalone',\n",
       " 'as a firsttime series reader i initially thought that the novel was a bad translation from a japanese original',\n",
       " 'it isn’tthe author is a california attorney who has a degree in asian studies from tufts university',\n",
       " 'br br the opening chapters have so many unfamiliar foreign words and names eg nyonindo koya myoin shinobi ryu iga and many more and so much description of special features of japanese mountain temple interiors and exteriors i couldn’t find the story that was supposedly there',\n",
       " 'the mystery of why two mismatched travellers a jesuit priest and a shinobi assassin would be traveling together to deliver some sort of lifeanddeath message while carrying a cat named “gato” seriously',\n",
       " 'in a wicker basket wasn’t enough to sustain my interestbr br to further complicate matters this is a historical mystery seriesa series which attempts to “remain faithful to shingon buddhist architecture doctrine life and practice as it existed on mount koya during the sixteenth century” lacking a college degree in asian studies i cannot offer any opinion on how well the author has succeeded in portraying th century shingon practice in japan',\n",
       " 'grownup anger the connected mysteries of bob dylan woody guthrie and the calumet massacre of purports to be a “cultural study” but it’s so personalizedstarting with an opening page chapter about the author’s gut response at age to dylan’s “like a rolling stone”that it reads like a memoir',\n",
       " 'starting from that remembered response author wolff embarks on an epic quest to discover the source of dylan’s anger and recounts all the details of his quest in this bookbr br wolff settles on the anger source as the “ massacre” that woody guthrie sang about because dylan used woody’s same melody in “song to woody”',\n",
       " 'the massacre was a real event in which children of striking copper miners and adult suffocated in a calumet michigan meeting hall stairwell',\n",
       " 'someone opened the hall doors and yelled ”fire” a false alarm and then antistrike men held the exit doors shut from the outside so that none could escapebr br however to take this single event and guthrie’s song as the source of the anger expressed by folk singers in the mids as “havenots” against the “haves” is a stretch to say the least',\n",
       " 'if anything author wolffs “revisionist history” shows that you can always find apparent “connections” between things if you try hard enough',\n",
       " 'wolff tells us in chapter that his four years spent at harvard college were wasted on him and i would agree',\n",
       " 'rattle is among the most pointless and depressing mysterythrillersuspense novels that i’ve ever read',\n",
       " 'the killer a hospital worker is a collector of human bones and skeletons that exhibit rare deformities particularly fibrodysplasia ossificans progressiva',\n",
       " 'he takes special delight in dissecting his specimens and has difficulty deciding whether “to keep or to kill” the living children he kidnaps for his collection because the children have obvious bone diseasebr br the story is told from multiple viewpoints the children their parents the detective investigating the case the killer and focuses on all of their dysfunctional family relationships',\n",
       " 'there’s a story there but it’s so dark and fantastical one wonders why anyone felt that it needed to be toldbr br the writing isn’t anything to shout about',\n",
       " 'the clumsy attempts at foreshadowing only make the plot hard to follow',\n",
       " 'the plot itself relies heavily on coincidences to move it forward and many plot events appear to be inserted just to fill out the word count',\n",
       " 'the story has some shock value but that by itself isn’t enough',\n",
       " 'for light reading i enjoy most fantasy mysterythriller and suspense novels but this novel is one that i wouldn’t recommend even for summer beach reading',\n",
       " 'i am no one a novel tells the story of an ordinary man jeremy who runs afoul of the ubiquitous presentday us government surveillance of its own citizensbr br returned to the us after spending years in england jeremy is teaching german history at new york university',\n",
       " 'however something about his data profile captures the interest of his governmental watchers and sets in motion a series of events that only confuse and puzzle their ohsoordinary subject jeremy',\n",
       " 'jeremy is in danger but doesnt know it let alone the why of itbr br unfortunately the entire page novel is told in firstperson mostly streamofconsciousness narrative',\n",
       " 'its a real slog because jeremy is so ordinary',\n",
       " 'the message of the book i think is that a world without personal privacy isnt worth living inbr br in my opinion that simple message isnt nearly enough to justify such a long book about a nobody',\n",
       " 'you can read the publishers product page description for a pretty good capsule summary of the actual events in the novel',\n",
       " 'i rate this boring novel at star i hate it on the official amazon scale',\n",
       " 'the author of murdercom is a retired new york city lawyer',\n",
       " 'the series title character reuben frost is a retired new york city lawyer',\n",
       " 'perhaps this explains what is wrong with this novel the author is a lawyer first a storyteller secondbr br the novel is literate but the story doesnt flow because the language is stiff and formal',\n",
       " 'at the beginning at least the plot is simplistic',\n",
       " 'frosts detective friend bautista tells him about his new murder case a woman with a ladbroke apartments address',\n",
       " 'frost wishes bautista luck then goes to dinner at the four seasons with a former client courtland',\n",
       " 'courtland chooses the excellently presented steak tartare frost goes for maryland crab cakes',\n",
       " 'courtland then asks frost to look into the very very recent disappearance of his adult daughter an editor who just moved into the ladbroke apartments',\n",
       " 'the two womens names are different but guess what',\n",
       " 'the murder victim is the clients daughter',\n",
       " 'so frost and bautista team up to solve the murder',\n",
       " 'except for the descriptions of characters backgrounds and expensive nyc restaurant dinners this is basically all that happens in the first pagesbr br the novel literally put me to sleep every time i picked it up',\n",
       " 'i even started it over again from the beginning to be fair but i just couldnt get into it and finally i gave up',\n",
       " 'because i found the characters to be flat and uninteresting and the plot too thin and obvious to keep me reading i rate murdercom at star i hate it on the official amazon scale',\n",
       " 'its a pity that the person who wrote the jacket blurb didnt write the entire book',\n",
       " 'clandestine is nothing more than an awful unreadable mess of a police procedural novel',\n",
       " 'the concept of a pair of detectives one french one german working together to solve ordinary runofthemill crimes that occur in occupied france during world war ii is highly intriguing if you have any taste at all for historical detective fiction',\n",
       " 'but this books writing is so opaque there is no pleasure to be gained from slogging through to try to locate the plotbr br as the story opens stcyr and kohler are arriving at a ruined monastery in the french countryside where theyve been summoned to investigate some bodies found near a banking company van',\n",
       " 'there is a policeman awaiting them',\n",
       " 'stcyr seems to have some kind of history with the policeman but its hard to figure out what that might be',\n",
       " 'i guess you need to have read one or more of the previous',\n",
       " 'books in this series',\n",
       " 'there are two bodies and the victims have been shot with antique firearms apparently by two assailants',\n",
       " 'the policeman who was first on the scene is lying to the investigators',\n",
       " 'it is unclear what the victims van was doing at the ruins or why it was carrying smuggled contraband in addition to bank notesbr br the most immediate problem that i had with this book is that you cant tell which character is speaking as you read the dialogue',\n",
       " 'similarly when you encounter interior monologues instead of dialogue you cant tell right away that youve gone inside a characters mind and you cant tell which character is doing the thinking',\n",
       " 'and its very hard to tell from the detectives backandforth banter which detective is in chargethe frenchman',\n",
       " 'or the germanbr br then theres the fact that historical background is added with factual passages like this recounting the german detectives thoughts while examining a murder victims body for the first time at the monasterys ruins the pockets had been turned out and emptied',\n",
       " '',\n",
       " '',\n",
       " 'everything',\n",
       " '',\n",
       " '',\n",
       " 'taken even the small change that was so necessary now if one was to ride the metro whose riders had gone from million a day in the autumn of to nearly million',\n",
       " 'br br for a little while i wondered whether this was simply a terrible translation',\n",
       " 'but the author is canadian so presumably the book was originally written in english',\n",
       " 'i ordered clandestine because it is supposedly part of a longrunning series',\n",
       " 'and because mysterious press is the publisher',\n",
       " 'but mysterious press really let me down this time',\n",
       " 'because this novel is unreadable for pleasure i rate it at star i hate it on the official amazon scale',\n",
       " 'when i ordered the jezebel remedy i was suckered in by the winstonsalem journals claim that martin clark had set the new standard by which other works of legal fiction should be judged',\n",
       " 'well i certainly hope notbr br what i look for in a mysterythriller isabove alla good story preferably a reasonably fastmoving story',\n",
       " 'i do not look for literary writing which not only adds pages of lavish description and dubious character analysis but also literally puts me to sleep',\n",
       " 'in the case of the jezebel remedy the literary writing not only bores me it makes me want to nominate the novel for next years bulwerlytton fiction contestbr br here is an example taken in part',\n",
       " 'from a single paragraph she passed the old dupont plant forlorn and empty beside a deep bend in the smith river the asphalt parking lot starting to split and crumble crabgrass spindly weeds and declining paint insolent behind chainlink fence the insides of the place eviscerated and hauled away machine after machine carted off and sold as scrap for pennies on the dollar',\n",
       " 'fortyfive hundred people had once worked three shifts there and in place of steady traffic lines every eight hours the lunch pails horseplay paychecks womanlessbeautypageant fundraisers softball teams break room gossip and casseroleandcongealedsalad company picnic was a dilapidated eyesore that would inevitably be razed and buried under redclay dirt rogue random chemicals left to seep into the water table and haunt the community',\n",
       " 'br br how does the author decide where to put the periods i wonder',\n",
       " 'this partiallyquoted paragraph is not atypicalyou can easily find many more paragraphs like it in the jezebel remedybr br the characters dont make sense to me either',\n",
       " 'take for example the dropdead gorgeous brilliant female lawyer who easily maneuvers an unwilling hostile expert witness into giving a deposition that supports her clients position',\n",
       " 'what the heck is she doing in a smalltown husbandandwife law practice representing walkin clients',\n",
       " 'and why does she tell herself that she really really loves her husband when shes irritated by his habits to the point where she never wants to hear him say heckuva job brownie to the dog again',\n",
       " 'to be sure she thinks the dogs name is geniusthe dog brownie is all black with one white spot',\n",
       " 'maybe the husband is right for her',\n",
       " 'br br because of the atrocious writing and because of the tooliterary approach to a mildly interesting mysterythriller i rate the jezebel remedy at star i hate it on the official amazon scale',\n",
       " 'recipes are by weight not by measurement',\n",
       " 'useless',\n",
       " 'the only reason i purchased this was to get the recipe for the iced coffee which is the best',\n",
       " 'i would have kept the whole book for that recipe but of course its not in the book',\n",
       " 'back it goes',\n",
       " 'you dont write a biscuit cookbook and use a purchased biscuit in a box as one of the ingredients',\n",
       " 'shame on the author',\n",
       " 'this was a bookclub pick',\n",
       " 'hardy was a cold unfeeling delusional narcissist',\n",
       " 'his wife was whiny powerless delusional',\n",
       " 'could not wait to reach the end',\n",
       " 'it took me longer to drive to the library peruse the shelves check out my books drive home and unload than it did to read this book',\n",
       " 'seriously',\n",
       " 'which isnt an altogether bad thing except that the sparse pages coupled with the after school special quality of the plot made me just shrug when all was said and donebr br i have to confess this is one of those times when i was blinded in my book choice by my own personal issues',\n",
       " 'my teenage daughter and i are going through a patch and i was caught by the books supertitle notes between a mother and daughter',\n",
       " 'be advised that little inclusion is not an exaggeration',\n",
       " 'the entire book is written in note form',\n",
       " 'youre left to do the detective work in filling in the plot between the scribbles',\n",
       " 'while i give the author points for trying this interesting concept it created too shallow of a storyline',\n",
       " 'first a definition from wikipediabr prescience is the full knowledge of all possibilities',\n",
       " 'throughout history a number of cultures have believed that oracles have possessed this ability',\n",
       " 'it is one of a number of psychic phenomena studied by parapsychology',\n",
       " 'although there is no scientific evidence for prescience this has not prevented a huge number of people in the modern world from believing in astrology and visiting fortune tellersbr br when i brought this book home from the library my girls asked what the title meant',\n",
       " 'i told them that i didnt know exactly i only knew it was supposed to be a mystery novel centered around the characters from pride and prejudice',\n",
       " 'after trying to read this book though i wish i would have looked at the title as closely as my children',\n",
       " 'to mix elizabeth and darcy with anything that leaned towards oracles psychic phenomena astrology or fortune tellers',\n",
       " 'that my friends is just wrong',\n",
       " 'but one thing at a timebr br i dont believe that barris presumed to think anyone would mistake her voice for jane austens',\n",
       " 'any of the modern books that try to follow the characters and storylines from austens classic novels seem built on the premise of we all know her stuff was better were just trying to have some fun here',\n",
       " 'and i think barris did a fairly decent job of keeping true to the charactersi mean sort of',\n",
       " 'it wasnt horrible',\n",
       " 'but it was like listening to a standup comic doing a passable imitation of someone else that is truly famousbr br other reviews ive read for this novel lambast barris disregard for keeping with the proper vernacular of austens time',\n",
       " 'this wasnt an element of the novel that bothered me the most but it did cross my mind',\n",
       " 'like little weeds creeping up through fertile soil modern snippets of conversation or even just exposition periodically slid into barris attempt at writing circaausten',\n",
       " 'ie one description of darcy spooning up next to elizabeth as she slid into bedbr br so the writing wasnt terrible the characters were recognizable but things for me started to unravel with the format of the mystery',\n",
       " 'nothing really smooth about many of the plot twists',\n",
       " 'more like blazing red arrows hovering above heads as if to say look at me',\n",
       " 'listen to me',\n",
       " 'i may be someone you want to remember for later',\n",
       " 'barris may as well have put big asterisks next to each conversation about gothic novels too as if to say hint hint hintcome and get your dark spooky mysterious fill right here',\n",
       " 'br br after a while it just got plain silly',\n",
       " 'right down to the part where the darcys corner the bad guy and he spills out all his dastardly plans in a two and half page monologue',\n",
       " 'and i like me some fantasy elements here and there in the right place and with the right story',\n",
       " 'but oh',\n",
       " 'my',\n",
       " 'word',\n",
       " 'this story ends with some incredibly laughable magical explanations for everything that has happened to the darcys in ye olde regency england',\n",
       " 'and elizabeths final thoughts of the book made me wince and give woe unto the idea that theres more to come',\n",
       " 'in quiet moments however she sometimes withdrew professor randolphs amulet and pondered his parting words to her',\n",
       " 'i believe you have a gift he had said',\n",
       " 'a very powerful one',\n",
       " 'should you ever choose to cultivate it let me know',\n",
       " 'perhaps one day she would',\n",
       " 'br br let me just tell it to you like this in my opinion this book isnt much more than the darcys meet scooby doo and gang',\n",
       " 'if only id had the prescience of mind to know that before i bothered to waste my time',\n",
       " '',\n",
       " 'this book should not be in a public elementary school for rd graders',\n",
       " 'did not like this cd book',\n",
       " 'too dark and did not finish it',\n",
       " 'i would not recommend this one my opinion',\n",
       " 'not at all what i expected',\n",
       " 'seems more like an autobiography than a cookbook',\n",
       " 'i’m not buying anymore cookbooks from carpenters',\n",
       " 'i am bewildered as to how to describe this book',\n",
       " 'i do not even understand the purpose of this text other than to say that the author describes macabre details as if reading a photograph',\n",
       " 'almost every paragraph is a new experience for the readerbr br for example in one paragraph the author writes about a kitten that was killed by a dog that was then autopsied by the pet owner and found to have internal organ damage',\n",
       " 'the author goes on to describe how the owner then photographed the dead kitten with sunglasses a cigarette in its mouth etcbr br in another paragraph in a different chapter the author talks about someone who told her a story about his father who was shouting for help while drowning and his family laughed and ignored him because they thought the father was clowning around since he was a trickster',\n",
       " 'he drowned of course',\n",
       " 'a few paragraphs later in the same chapter is an excellent description of how waterboarding is donebr br the short narratives go on and on throughout the book',\n",
       " 'i just started reading this and stopped at page',\n",
       " 'i browsed other paragraphs in the book but it was more of the same disaster type stories death starvation prison etc',\n",
       " 'this is not a book i want to read further',\n",
       " 'the subject matter is incredibly gruesome to me and the text is all over the place as the reader moves from one varied narrative to another',\n",
       " 'i do not feel i am learning anything at all from the text even though this is sadly a work of nonfictionbr br on the positive side it is apparent from the bibliography that the author did a lot of research before producing this text',\n",
       " 'in addition she writes exceptionally well but the narrative is just a compilation of one ghastly detail after another with no continuity inbetween',\n",
       " 'this is definitely not a page turner for me although a select few might consider it a masterpiece',\n",
       " 'scent of the missing is supposed to be about the author and her dogs adventures relationship and search and rescue sar work',\n",
       " 'however there is nothing adventurous about the story and not much interesting about the relationshipbr br until chapter the story is a hodgepodge of different facts about the authors life that have very little to do about the adventures of puzzle the dog',\n",
       " 'suzanne talks about the golden retriever and its history emails she sent to find the right dog the fact that shes divorced then she mentions suicide that takes up about sentences etc etc',\n",
       " 'i felt i was getting whiplash as the author bounced from one unrelated fact to the next usually within the next sentence',\n",
       " 'without a transition to let the reader know she was going to talk about something else entirely the reader is left frustrated bored and confused when reading this bookbr br three examples of what i mean by the above arebr br when the author told the story about puzzle coming home for the first time in one paragraph you are on the plane and in the next paragraph she starts talking about puzzle sniffing the poms butt pom meaning her pomeranians at homebr br in one story she tells about sar work she did when looking for a man who allegedly was drowned in the water under his boat',\n",
       " 'the chapter ends with the message that she will be told by the divers about whether they find this man or not in the water',\n",
       " 'however you never find out because the next chapter starts another boring nonsensical story about housebreaking a golden retrieverbr br in another story suzanne rehashes a car conversation she has with another sar worker then mentions the storm of in another sentence then talks a little about the boring sar work that nightbr br the four barely okay parts to this book arebr br the one good paragraph about when she picked up scuppy an old blind dog who was going to be euthanized at the shelterbr br the cute way puzzle came home on the airplanebr br the search for mrs celeste in chapter an old lady suffering from alzheimersbr br the information about what its like to do sar work in chapter br br in summary i highly commend the author for the sar work she her dog and her teammates do however this book lacks any gripping story about that work and the writing is dreadful and totally unemotional',\n",
       " 'i am actually shocked that other authors have endorsed this book on the back cover and cant believe a publisher would publish this book unless the author paid for itbr br if you are still interested in scent of the missing borrow it from the library because if you purchase it you probably will wish you hadnt',\n",
       " 'ive already thrown it out',\n",
       " 'i ordered this book over one year ago because of the rave reviews',\n",
       " 'i tried two recipes in it',\n",
       " 'the lemon pound cake was dense too lemony and just all around not to my or my boyfriends liking',\n",
       " 'the vanilla cupcakes were so so',\n",
       " 'i make exceptional desserts from recipes in other books and articles and people have raved about them',\n",
       " 'i also follow instructions precisely',\n",
       " 'however in this case i know that the recipes are not good at least to me and the baker is not the problem',\n",
       " 'i guess i just dont have a taste for the recipes in this book',\n",
       " 'i am almost afraid to try another recipe because the two others have been so disappointingbr br perhaps this book is for someone who has different tastes from the norm',\n",
       " 'however i like decadent desserts',\n",
       " 'so far im thoroughly disappointed and wished i hadnt purchased the book',\n",
       " 'my kids didnt even look at this one they did not care for it',\n",
       " 'how rude taht the author prescribed that the universal format is to put japanese name in the order of st name first',\n",
       " 'in a world where asian population is dominant they all display their last name first',\n",
       " 'how presumptuous and arrogant just set me off on what other biases he had in writing this book',\n",
       " 'i just could take it seriously after i read the note',\n",
       " 'interesting read that i will take a pinch of salt as it does not appear to be objective',\n",
       " 'from magic toadstools with psychedelic powers to teaching stealing is ok and destroy the evidence to an almost predator like grooming way of writing that screams of princesses being kidnapped are nothing to be alarmed by',\n",
       " 'this book is rather alarming to be aimed at kids',\n",
       " 'my least favorite book out of ive bought',\n",
       " 'not loving the images',\n",
       " 'a couple ok ones',\n",
       " 'i wouldnt recommend it',\n",
       " 'was really torn up looking like it came out of the garbage',\n",
       " 'cliche after cliche nothing new or inspiring not touching at all',\n",
       " 'disappointing',\n",
       " 'this is written in more of a peerrevieweddissertation format',\n",
       " 'my students were not interested in reading this edition',\n",
       " 'i went back to the earlier edition which my students were more than willing to read',\n",
       " 'sorry',\n",
       " 'i love the earlier edition and continue to use it',\n",
       " 'my students save the earlier edition as well for use in their classrooms',\n",
       " 'the book is extremely small cheap with print impossible to read without a magnifying glass',\n",
       " 'i was dupedbr i have purchased many penguin books clothcovered normalsized and absolutely lovely',\n",
       " 'i used to really enjoy this authors books',\n",
       " 'his last few have become progressively more political',\n",
       " 'one doesnt want to read in a book about everything you hear on the news',\n",
       " 'books are for escaping and enjoying a different experience',\n",
       " 'extremely disappointing to the point that i wont be buying any more of this authors books',\n",
       " 'i have read this series from the beginning',\n",
       " 'the last two books have been very disappointing',\n",
       " 'ms stabenow seems to have developed a liking for the f word and gd',\n",
       " 'im not prude but the repetitious use of both of those things seemed really unnecessary',\n",
       " 'as others have mentioned the author appears to be lacking enthusiasm',\n",
       " 'the previous book was a bit better but im struggling to get through this one',\n",
       " 'i dont think ill buy any more books in the series if she writes more',\n",
       " 'this is a great series',\n",
       " 'but i dont understand how amazon can allow book sellers to charge or for this book',\n",
       " 'that just seems absolutely outrageous',\n",
       " 'the book is no longer in print and id love to be able to read it but not at these prices',\n",
       " 'this is the worst book of the series',\n",
       " 'im not sure why box had to include political themes',\n",
       " 'the book didnt require it',\n",
       " 'also the writing itself was not up to par',\n",
       " 'the book dragged and some of the characters were so lame',\n",
       " 'i wondered if box wrote it',\n",
       " 'also the book ends with a cliff hanger',\n",
       " 'i feel i wasted dollars',\n",
       " 'i was a big fan of the prey books until sandford went to the dark side',\n",
       " 'his books have gotten extremely raw and unsettling',\n",
       " 'in his earlier books he was able write a great story without having to become so dark',\n",
       " 'so im done',\n",
       " 'i have read all of margaret coels wind river reservation series and enjoyed them all',\n",
       " 'this seemed like it wasnt ever written by her',\n",
       " 'id recommend looking into that series over this book',\n",
       " 'i have read all of ms barrs anna pigeon books and enjoyed them',\n",
       " 'but this one i couldnt get through',\n",
       " 'barr is an excellent writer but this topic and its darkness is not what i want to read about',\n",
       " 'i have heard ms barr speak',\n",
       " 'she has a wonderful sense of humor is an excellent speaker and had the audience in the palm of her hand',\n",
       " 'as others have said please get back to the anna pigeon we know and love',\n",
       " 'dull and simple',\n",
       " 'sorry i just dont like this book',\n",
       " 'seems like a child could have written this',\n",
       " 'this book is really awful',\n",
       " 'it isn’t as cute or clever as the original',\n",
       " 'and the message comes across as super passive aggressive',\n",
       " 'pretty sure all the positive reviews are grandparentsbr the granny donkey has nothing to do and gets grumpy when her son and granddaughter don’t visit her enough',\n",
       " 'apparently her granddaughter has no mother as there is no mention of her at all',\n",
       " 'granny donkey is only grinning and happy when her son and granddaughter make time to visit her',\n",
       " 'insert my eyeroll here',\n",
       " 'br it doesn’t portray healthy relationships',\n",
       " 'it doesn’t portray the granny donkey in a good light',\n",
       " 'she’s more of a bored toddler pitching a fit than an adult with her own life and ability to visit people herself',\n",
       " 'and it isn’t funny or clever so there is nothing really redeeming going on',\n",
       " 'the wonky donkey was cute',\n",
       " 'this isn’t',\n",
       " 'im not thrilled with this book',\n",
       " 'my kids love logic so i thought this would be right up their alley',\n",
       " 'many of the brain teasers have to be seen to be understood so it isnt something you can really read aloud or use for a classroom',\n",
       " 'the alien narrating the book gives you their pronouns in their introduction',\n",
       " 'they also use really weird names that are hard to pronounce and use made up words for the aliens and their planet which make some of the brain teasers really incoherent',\n",
       " 'my kids didnt like the puzzles all that much',\n",
       " 'most of them were super simple which isnt any fun',\n",
       " 'we just didnt have much fun with this book',\n",
       " 'this is a very poorly written pregnancy book',\n",
       " 'some of the info is out fo place telling you are itching and cholestasis in month one is not really where that should go since the itching and cholestasis are usually more of third trimester problems',\n",
       " 'some of it just isn’t good or even that funny',\n",
       " 'as a humor book it pretty much fails',\n",
       " 'as a pregnancy book it pretty much fails',\n",
       " 'skip this one',\n",
       " 'and if you choose to read it please please please don’t let this be the only pregnancy book you read',\n",
       " 'i have a hard time placing my finger on why i disliked this book so much',\n",
       " 'i will try but overall i disliked it much more than i can even convey',\n",
       " 'so much of the book was just the author talking about herself',\n",
       " 'i felt like the first two chapters were spent with her trying to tell you why she is the expert despite her not having much to say',\n",
       " 'when you finally get into the “meat” of the book all the advice simply boils down to clean eating with some bible verses thrown in to make it a christian approach and not the approach of most other diets on the market',\n",
       " 'there isn’t enough information in the book to consider it more than just a basic intro to clean eating which you can probably get for free from bloggers if you just look up the term “clean eating”',\n",
       " 'there are some recipes in the book but none that are really revolutionary or even more than basicbr if you’re looking for this info trim healthy mama does a better job and has a more unique approach',\n",
       " 'i’m used to odd books',\n",
       " 'as a homeschool mom some of the best resources are a little odd',\n",
       " 'this one does not fit that category',\n",
       " 'i’ll go with the positive first',\n",
       " 'introducing state capitals as people is clever',\n",
       " 'it does lend itself to better memory if you’re a person who learns people and names better than facts',\n",
       " 'that is where the positives end with this bookbr you’ve got five friends who each tour a different region of the us visiting their friends',\n",
       " 'each two page spread features a new state with a lot of info for each state',\n",
       " 'the information is good but the way it is presented is just overwhelming and not easily processed',\n",
       " 'it is very poorly writtenbr the illustrations are terrible',\n",
       " 'the font choices are awful',\n",
       " 'the graphics are very dated',\n",
       " 'pretty sure i remember doing block wave graphics on my first computer back in junior high',\n",
       " 'the entire look of this book is terrible',\n",
       " 'it is just a jumbled mess of information',\n",
       " 'luci swindoll gives you motherly advice on how to have a happy life',\n",
       " 'in short chapters swindoll passes on lifes secrets to youbr br only luci swindoll isnt a mother',\n",
       " 'and luci swindoll is telling you all the things a mother tells her children',\n",
       " 'none of this is revolutionary',\n",
       " 'some of it is even counter productive',\n",
       " 'im not sure miss swindoll has much grounds to give anyone life advice',\n",
       " 'it seems her only qualification is that she has lived',\n",
       " 'i know this sounds harsh and it is nothing agianst miss swindoll im sure shes a swell woman',\n",
       " 'im just not sure what publisher thought this book was a good idea to publishbr br honestly luci lost me at number one',\n",
       " 'it was just bad advice honestly',\n",
       " 'chapter one was honor your father and mother',\n",
       " 'the advice given might have been great for those that have relatively normal parents and normal circumstances',\n",
       " 'but it is downright terrible advice for those of you who have abusive narcissistic or sociopathic parents',\n",
       " 'of course miss swindoll cannot possible know all of our circumstances but she comes at it from the angle of knowing someone with a difficult relationship with her horrible mother and he still honored her and she took the verbal abuse to take care of her',\n",
       " 'i think miss swindoll is downright wrong on this one',\n",
       " 'she claims you dont have to like them but you should continue to honor and respect them',\n",
       " 'she doesnt mention abusive manipulative controlling parents who make your life miserable',\n",
       " 'if you are dealing with parents of this type try boundaries by cloud and townsend and ignore miss swindolls advicebr br luci goes one to talk about being on time taking jesus everywhere keeping your work reading your bible everyday value what you have allow yourself to be sad writing down important things establishing integrity in your life thinking before you speak and so on',\n",
       " 'none of this is new',\n",
       " 'none of this is more than any of us have been told all our lives',\n",
       " 'honestly it seems like this book is lucis baby',\n",
       " 'shes telling all the motherly advice in book form that she never got to personally share as a mother',\n",
       " 'i just cant see how this is helpfulbr br i really didnt like this book',\n",
       " 'this feel good superficial commonsense reading just isnt for me',\n",
       " 'maybe there is an audience for this somewhere it just isnt found in mebr br disclosure of material connection i received this book free from the publisher through the booksneeze®com book review bloggers program',\n",
       " 'i was not required to write a positive review',\n",
       " 'the opinions i have expressed are my own',\n",
       " 'i am disclosing this in accordance with the federal trade commissions cfr part',\n",
       " 'i have owned several of these dummies books but on this one i had to ask myself why i bothered',\n",
       " 'this book has nothing new or revolutionary to offer',\n",
       " 'i cant imagine it helping anyone learn to sell any better',\n",
       " 'it says books in but none of them are worth much',\n",
       " 'if you really need help selling look elsewhere',\n",
       " 'this book i thought had promise',\n",
       " 'boy was i wrong',\n",
       " 'this book is really two books in one',\n",
       " 'one is the actual story following a guy named ben in a world full of zombies',\n",
       " 'the second is the devotional book that uses the fictional story as a lesson about the state of our soulsbr br first from a theological standpoint kinley is coming from a different place than i am',\n",
       " 'he assumes a lot in his theology that i just wouldnt say is so',\n",
       " 'you may find yourself starting from the same assumptions he does in which case youll probably follow along better with the devotional aspect of the book',\n",
       " 'i just found the theological difference to be too much for me to get anything from the book devotionally',\n",
       " 'i am free church wesleyan if that makes a difference to you',\n",
       " 'br br second the allegory is such a stretch',\n",
       " 'and kinley tries to make it all so literal and really stretch it',\n",
       " 'it just doesnt work well and feels very stretched and very manipulatedbr br third the story is lacking',\n",
       " 'if you are reading it for the fictional zombie story dont bother',\n",
       " 'kinley isnt the best story teller',\n",
       " 'character development is what youd expect reading an amateurs novel',\n",
       " 'the plot doesnt even make sense at times because it is being stretched to fit the allegorybr br overall the book was not enjoyable at all on any level',\n",
       " 'i didnt enjoy the story telling aspect',\n",
       " 'i didnt enjoy the devotional aspect',\n",
       " 'the premise of this book was a good one',\n",
       " 'a book to tell women all those weird pregnancy things and assure you they are okay',\n",
       " 'however vicki chose to go a different route',\n",
       " 'she is very clearly against natural childbirth and takes a mocking tone toward it',\n",
       " 'according to the book she only knows two women who tried natural childbirth and they both ended up with csections and regretted trying',\n",
       " 'every one of her birth stories is about someones failed attempt at childbirth',\n",
       " 'this book is full of terrible advice',\n",
       " 'despite what this book says you can get to the hospital too early',\n",
       " 'despite what this book says all doctors are not good doctors',\n",
       " 'despite what this book says many women have a medication free childbirth',\n",
       " 'despite what this book says many studies show that being away from the hospital and doctors is safer',\n",
       " 'despite what this book says you do get to have a say in your pregnancy and childbirth even if it is your first baby',\n",
       " 'this book sets up the idea that childbirth is unbearable and you should be scared and therefore get an epidural or just schedule your csection',\n",
       " 'the author also claims that exercise during pregnancy will have no effect on your labor and delivery',\n",
       " 'maybe vicki is just illinformed',\n",
       " 'or maybe she want to change the birth climate so everyone has disappointing births where they felt no control',\n",
       " 'either way this book is one of the worst pregnancy books on the market',\n",
       " 'this was literally the worst book ive ever read and the most offensive',\n",
       " 'its like the author set out to purposely offend as many groups as possible',\n",
       " 'this book is full of incest rape homophobia racism and antisemitic language',\n",
       " 'i only finished reading it out of pure morbid curiosity',\n",
       " 'also the general flow is extremely stilted and the author should have taken a class on punctuation and writing before writing this book',\n",
       " 'if you really want to waste money on offensive filth its your dime but i strongly recommend putting your money elsewhere',\n",
       " 'this book is also incredibly boring and rehashes the same point over and over until you just want to scream',\n",
       " 'a five year old could write a better book than this',\n",
       " 'seriously',\n",
       " 'the only reason i gave this book one star is because it wouldnt let me give stars',\n",
       " '',\n",
       " 'sorry this book is just disappointing too much about fishing rather than murder solving',\n",
       " 'i find the characters boring as all get out',\n",
       " 'was all used when we got it',\n",
       " 'i thought i was ordering a math book',\n",
       " 'this is not what i wanted or what i was expecting',\n",
       " 'geez',\n",
       " 'whats all the hype about',\n",
       " 'absolutely nothing happened',\n",
       " 'this is like softcorefauxporn for housewives that had a herd of babies in their s instead of exploring and discovering who their sexual selves are in a healthy and safe way of course',\n",
       " 'i forced myself to finish just so that i could give it an honest review and in the hopes of getting to some meat no pun intended and finding that i was compelled to read the next in the series',\n",
       " 'but nope',\n",
       " 'that definitely did not happenbr additionally i am forgiving of firsttime published authors however there was so much ramble so much unnecessary detail and none at all where it counts and repetition of adjectives often on the same page that id be hard pressed to even consider reading this author in the future',\n",
       " 'i was really into it',\n",
       " 'i let go of the fact that there arent descriptions of what people look like and felt maybe the author did that on purpose to let us imagine who we wanted',\n",
       " 'i let go of the fact that the descriptions of surroundings were not consistent and some situations were not quite realistic',\n",
       " 'however i cant let go that it seemed when the biggest moment in this story happened the author just rushed right through it all',\n",
       " 'never answering many questions about characters that they kept bringing up in the book then blazed right through a huuuge moment to just get to the end',\n",
       " 'it felt the author was tired of writing the story and just wanted to skip today a big fantasy ending that wasnt very impactful when they didnt really fill out the important parts',\n",
       " 'disappointed as this idea really could have been done well and thorough even if it took another pages to do so it would have been more filling and rewarding',\n",
       " 'its like reading a game of boggle or unscrabbled',\n",
       " 'i would like this book replaced with one of proper material that is not broken',\n",
       " 'i did not pay for a damaged book',\n",
       " 'i paid for a book in great shape',\n",
       " 'one that is treated with respect',\n",
       " 'thank you',\n",
       " 'i received this book and it was upside down and the end was where the beginning was suppose to be andbr i just threw it away and amazon credited me',\n",
       " 'just depressing and ugly',\n",
       " 'nothing enjoyable exciting or movingglad to have it in my rear view mirror',\n",
       " 'glad it was only pages',\n",
       " 'spending a weekend with a year old so messed up her equally messed up mother and her equally messed up bff',\n",
       " 'it just got worse and worse as i read',\n",
       " 'skyhorse publishing inc is an american independent book publishing company founded in',\n",
       " 'grim',\n",
       " 'whatever made me order this unpleasant story i regretted it fully by the last page',\n",
       " 'there is nothing palatable or compelling or intriguing or insightful',\n",
       " 'published in as wasted in south africa',\n",
       " 'nathan is a freak someone to be avoided in life and he is the narrator',\n",
       " 'i felt unclean',\n",
       " 'this book is missing pages goes from to what the hell',\n",
       " 'just plain boring',\n",
       " 'i usually dont read his books with other authors and will return to that practice after this',\n",
       " 'it is not a james patterson book',\n",
       " 'one of the worst books that i have read in a long time',\n",
       " 'i was a big fan of her early books and gave up on the series a few books ago',\n",
       " 'lacking anything better to read i picked this one up and found it to be the worst one yet',\n",
       " 'marmee wasnt scary because all she did was give anita an excuse to screw more men and the other bad guys didnt enter the story until nearly the end',\n",
       " 'in other words very little actionbr br i have never read this series for the sex i enjoyed the action',\n",
       " 'it was nice to see a strong female character',\n",
       " 'anita is no longer strong just sex starved',\n",
       " 'do not buy this book if you are hoping to teach your child about the different types of trains',\n",
       " 'the pictures are not the greatest as well',\n",
       " 'not what i expected for the money',\n",
       " 'this book has recipes that were copied from fork to spoon by laurie fleming',\n",
       " 'do not support this plagiarism',\n",
       " 'i have a hard time finding a really good book but bought this based on the recommendations',\n",
       " 'what a disappointment',\n",
       " 'i did finish it just for the sake of finishing but wasn’t worth reading',\n",
       " 'it was an easy read but not a compelling read',\n",
       " 'wish i could get a refund would never recommend this to anyone',\n",
       " 'i heard alot about this book and was looking forward to reading it and it was so hard to even finish it',\n",
       " 'i thought it was just a coloring book and its more of a story book with a few things to color',\n",
       " 'other than a couple of diagrams and simple charts on the first few pages this is only a journal',\n",
       " 'sure its broken down into sections of put your ingredients here and detail how to prepare it here etc etc',\n",
       " 'but if youre looking for creative suggestions of ingredients to pair or techniques to use in developing recipes this is a hard pass',\n",
       " 'if youre looking for a nice journal for developing and centralizing your recipes this could have been the oneexcept that the binding doesnt allow the book to be flat so good luck actually writing in it',\n",
       " 'its terribly expensive for what it is',\n",
       " 'if youve read the book this is redundant',\n",
       " 'threw it out after pages',\n",
       " 'boringbr no story dull characters pages of drivel about erratic hurricane',\n",
       " 'just awful',\n",
       " 'boring',\n",
       " 'spent the book inside the mind of a year abduction victim',\n",
       " 'too depressing',\n",
       " 'story predictable',\n",
       " 'i love reacher novels',\n",
       " 'this one was predictabletoo little story too much marshall arts descriptions',\n",
       " 'this us not a novelbut a short story of less than pages in a reduced size cover',\n",
       " 'its a stupid take off of a previous short storythinner',\n",
       " 'but its a really stupid story',\n",
       " 'last king book ill buy last two arent with the bucks',\n",
       " 'tedious and boring',\n",
       " 'we received bobby the bunny instead of the shown katy the kitten',\n",
       " 'my granddaughter was disappointed especially when we found out it was unavailable',\n",
       " 'cover torn corner crumpled cover completely separated from book',\n",
       " 'put in for replacement',\n",
       " 'disclaimer i like snark',\n",
       " 'i happen to be a practitioner of the fine art of sarcasm',\n",
       " 'this wasnt snarkits entitled whiningbr this being said there was nothing in what i read redeemable about these characters',\n",
       " 'i got chapters in and i just wanted them all to get a raging case of heroes then get hit by a freak storm of heavy booksgood books for the irony',\n",
       " 'books with likeable characters',\n",
       " 'this book was boring and didnt have much substance',\n",
       " 'it could have been said in pages or less',\n",
       " 'this book is so dull',\n",
       " 'edward is a restraining order waiting to happen',\n",
       " 'hard pass',\n",
       " 'the sample is mystical midlife in maine but the download is midlife witchery yule tidings',\n",
       " 'dont know how this got mixed up on amazon downloads but it did',\n",
       " 'please get this fixed',\n",
       " 'it is unfortunate that this book attempts to be about the great escoffier',\n",
       " 'i found it degrading and poorly written',\n",
       " 'the story line did not hold together',\n",
       " 'i would hate to have people remember escoffier based upon reading this book',\n",
       " 'i was disappointed with this latest book',\n",
       " 'i was expecting more information and less journal pages',\n",
       " 'i felt like it was another celebrity rip off',\n",
       " 'i will most likely not buy any more products from paula deen',\n",
       " 'i just saw the movie expelled yesterday and ben stein interviewed richard dawkins that author richard looked like a idiot',\n",
       " 'watch expelled first and you will not buy a book written by this dork',\n",
       " 'this is a very warped story about the authorbrenner having sex with a dolphin',\n",
       " 'yes a dolphin',\n",
       " 'he has an intimate relationship with the dolphinin every sense of the word intimatebr br loving anything or anyone is different than having sex with the object of your emotion',\n",
       " 'and having sex with animals just doesnt fit into the description of a relationship',\n",
       " 'just like having sex with kids doesnt fit into the description of a relationshipbr br the author here writes a novel about his real love and sex with a dolphin',\n",
       " 'in his twisted mind the dolphin and he had a romantic relationship',\n",
       " 'yes they shared love attraction and mutually consentual sexual gratificationbr br this is more than the author wants to tell you about the book and probably more than you need to know about this bookbr br take a big pass on this walk down a very warped pathbr br however if you are into having sex with animals youre gonna love this book',\n",
       " 'there is nothing good to say herebr br the artwork is bad for startersbr br there are bookmarks per page and they are tear apart',\n",
       " 'i dont think that this is acceptable for a bookmarkbr br plus they are kind of short for a bookmark only inches i should have paid more attention when orderingbr br the list price is so not a bargain here',\n",
       " 'it is currently on a for deal which helps if you like ugly short tear apart bookmarks',\n",
       " 'i loved steve martin but i hate this book',\n",
       " 'after since reading this i dont hold him in such high esteem anymore',\n",
       " 'this book feels like something i could have printed up on my printer',\n",
       " 'there are food pictures but theyre all in black and white not in color like the cover so they dont make a difference',\n",
       " 'also the print is so small it makes it very hard to readbr br ill try it out but so far im not impressed',\n",
       " 'if you like lies this is chock full of them',\n",
       " 'i tried writing a detailed review but it was not published so heres a simple reviewbr br this is a prowhite book of white supremacy disguised as historybr br thats all folks',\n",
       " 'this is a disaster of a book',\n",
       " 'i made the vanilla cupcake recipe',\n",
       " 'the first time i made them they sunk',\n",
       " 'i thought i might have added too much baking soda so i gave them another try',\n",
       " 'the second time it looked like they sank and then rose again',\n",
       " 'i followed the directions precisely to the letter',\n",
       " 'i made them with all fresh ingredientsbr br im going to try to return this to amazon because it is so bad',\n",
       " 'this tells me never to trust the reviews of the people on this site',\n",
       " 'more history than recipes in book',\n",
       " 'disappointed',\n",
       " 'not much information just a few pictures',\n",
       " 'very small book',\n",
       " 'there was dirt cacked up on the covered under the small dust cover',\n",
       " 'the artwork of these stickers aren’t great',\n",
       " 'the story is very typical of many other stories i have read revolving around abuse',\n",
       " 'what bothered me the most is the print and writing style of this book',\n",
       " 'there are errors i found',\n",
       " 'saying color instead of collar and the print is terrible',\n",
       " 'very disappointing',\n",
       " 'large bubble on the side of the face scratched up and filthy and the bottom',\n",
       " 'do not purchase this used',\n",
       " 'not all of the little papers are included',\n",
       " 'there was a small folded paper from the wizardology book inside for some reason',\n",
       " 'very disappointed',\n",
       " 'you get what you pay for',\n",
       " 'very disappointed',\n",
       " 'i expected more out of this book for the price it is',\n",
       " 'the author mostly just rambles and jumps from one subject and movie to another',\n",
       " 'it was a bore',\n",
       " 'this book is very mediocre and full of typos',\n",
       " 'highly disappointed',\n",
       " 'not worth a penny',\n",
       " 'seems like whoever wrote this just threw together random facts from the s and didnt bother to proofread it',\n",
       " 'way too small',\n",
       " 'if you wear a medium you have to get like a xl for this',\n",
       " 'horrible',\n",
       " 'the pics or very basic and not cute',\n",
       " 'i could draw one better and i cannot draw well',\n",
       " '',\n",
       " 'the only thing that is worthwhile with this book is the pretty cover',\n",
       " 'i ordered two books one for myself and one for a friend',\n",
       " 'both books got tossed into the goodwill bag',\n",
       " 'huge disappointment',\n",
       " 'im so disappointed in this book',\n",
       " 'i thought it would make a great gift for another dog lover friend of mine one who is always sending me cute dog cartoons',\n",
       " 'but i thought i would pick up a used copy for myself first so i could actually read them',\n",
       " 'perhaps im not sophisticated enough for the new yorker brand of humor',\n",
       " 'most of the cartoons contained in this book do not resonate with me at all',\n",
       " 'perhaps im exceptionally slow but some i dont even understand',\n",
       " 'i find very few of them at all funny',\n",
       " 'some seem to me to be at the expense of dogs',\n",
       " 'i doubt if most of these are actually written and drawn by dog lovers it feels more like insensitive people trying to appear witty',\n",
       " 'there is a fairly large variety in this book so you might find something that you like',\n",
       " 'i found a couple',\n",
       " 'but overall i found this collection extremely disappointing',\n",
       " 'i will not buy another copy for my friend and do not recommend it',\n",
       " 'i was going to purchase the new yorker book of cat cartoons but am now rethinking that',\n",
       " 'thumbs down on this book',\n",
       " 'the entire concept of someone able to live on after theyd died at birth or by accidental drowning or whatever',\n",
       " 'and reappear was just too much',\n",
       " 'i couldnt wrap my brain around it and found it just darn tedious',\n",
       " 'after reading about half the book i just couldnt go on and decided not to waste anymore of my time',\n",
       " 'down the drainbr br awful',\n",
       " 'just awful',\n",
       " 'i tried to read this book on multiple occasions',\n",
       " 'i never made it past the first dozen or so pages',\n",
       " 'i was bored to tears',\n",
       " 'that is something i never thought id say about a paul theroux book',\n",
       " 'ive read a number of his books and lovedvery much liked each',\n",
       " 'not under the wave at waimea',\n",
       " ...]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_tokens(df['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "603a1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X = tfidf.fit_transform(df[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7c466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaierardi/miniforge3/envs/genai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df2b8e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e33d027",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79c2c1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.60      4809\n",
      "           1       0.51      0.08      0.13      3127\n",
      "           2       0.58      0.78      0.67      5841\n",
      "\n",
      "    accuracy                           0.57     13777\n",
      "   macro avg       0.55      0.50      0.47     13777\n",
      "weighted avg       0.56      0.57      0.52     13777\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      4809\n",
      "           1       0.42      0.19      0.27      3127\n",
      "           2       0.60      0.75      0.67      5841\n",
      "\n",
      "    accuracy                           0.58     13777\n",
      "   macro avg       0.54      0.52      0.51     13777\n",
      "weighted avg       0.55      0.58      0.55     13777\n",
      "\n",
      "\n",
      "Logistic Regression w\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59      4809\n",
      "           1       0.34      0.42      0.38      3127\n",
      "           2       0.66      0.58      0.62      5841\n",
      "\n",
      "    accuracy                           0.55     13777\n",
      "   macro avg       0.53      0.53      0.53     13777\n",
      "weighted avg       0.56      0.55      0.55     13777\n",
      "\n",
      "\n",
      "Linear SVM\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59      4809\n",
      "           1       0.40      0.21      0.27      3127\n",
      "           2       0.60      0.73      0.66      5841\n",
      "\n",
      "    accuracy                           0.57     13777\n",
      "   macro avg       0.53      0.52      0.51     13777\n",
      "weighted avg       0.55      0.57      0.55     13777\n",
      "\n",
      "\n",
      "Random Forest\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55      4809\n",
      "           1       0.48      0.05      0.08      3127\n",
      "           2       0.54      0.80      0.64      5841\n",
      "\n",
      "    accuracy                           0.54     13777\n",
      "   macro avg       0.52      0.46      0.42     13777\n",
      "weighted avg       0.53      0.54      0.48     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "classes = df['sentiment'].unique()\n",
    "weights = compute_class_weight('balanced', classes=classes, y=df['sentiment'])\n",
    "dict(zip(classes, weights))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Target labels\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_SEED),\n",
    "    \"Logistic Regression w\": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED),\n",
    "    \"Linear SVM\": LinearSVC(random_state=RANDOM_SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    print(f\"\\n{name}\\n\", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5217e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59      4809\n",
      "           1       0.34      0.42      0.38      3127\n",
      "           2       0.66      0.58      0.62      5841\n",
      "\n",
      "    accuracy                           0.55     13777\n",
      "   macro avg       0.53      0.53      0.53     13777\n",
      "weighted avg       0.56      0.55      0.55     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "classes = df['sentiment'].unique()\n",
    "weights = compute_class_weight('balanced', classes=classes, y=df['sentiment'])\n",
    "dict(zip(classes, weights))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Target labels\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a67386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.58      0.58      4809\n",
      "           1       0.34      0.41      0.37      3127\n",
      "           2       0.66      0.59      0.62      5841\n",
      "\n",
      "    accuracy                           0.54     13777\n",
      "   macro avg       0.53      0.53      0.52     13777\n",
      "weighted avg       0.56      0.54      0.55     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "classes = df['sentiment'].unique()\n",
    "weights = compute_class_weight('balanced', classes=classes, y=df['sentiment'])\n",
    "dict(zip(classes, weights))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"clean_text\"], df[\"sentiment\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000,  class_weight='balanced', random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3bc0e3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_model.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"sentiment_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'sentiment': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8002/predict\"  # note: 8000\n",
    "payload = {\"text\": \"This is quite good, but can be. \"}\n",
    "\n",
    "r = requests.post(url, json=payload)  # JSON, not form data\n",
    "print(r.status_code)   # should be 200\n",
    "print(r.json())        # {'sentiment': 'positive'} (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b3f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every page has a crease running the entire length of the book about an inch and a half from the edges.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "812dce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "data['sentiment_pred']= pd.Series(pipeline.predict(data['text'])).replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "37bbf3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82      4000\n",
      "     neutral       0.52      0.80      0.63      2000\n",
      "    positive       0.90      0.77      0.83      4000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.76      0.78      0.76     10000\n",
      "weighted avg       0.81      0.77      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data['sentiment_str'], data['sentiment_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "563e008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df['sentiment_pred']= pd.Series(pipeline.predict(df['sentence'])).replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "dfd48cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.71      0.46     23717\n",
      "     neutral       0.23      0.15      0.18     15581\n",
      "    positive       0.43      0.13      0.20     29583\n",
      "\n",
      "    accuracy                           0.33     68881\n",
      "   macro avg       0.33      0.33      0.28     68881\n",
      "weighted avg       0.35      0.33      0.29     68881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['sentiment_str'],df['sentiment_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "55611363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency: 3.51 ms\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "\n",
    "texts = df['clean_text'].iloc[1000]\n",
    "start = time.time()\n",
    "for t in texts:\n",
    "    requests.post(\"http://127.0.0.1:8002/predict\", json={\"text\": t})\n",
    "end = time.time()\n",
    "print(f\"Average latency: {(end-start)/len(texts)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2e83aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download if not already done\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove special characters, punctuation, digits\n",
    "    text = re.sub(r'\\d+', '', text)  # remove digits\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove non-alphabetic characters and extra spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove stopwords and apply stemming\n",
    "    tokens = text.split()\n",
    "\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "82ee1785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/andreaierardi/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Downloads (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "CONTRACTIONS = {\n",
    "    \"can't\":\"cannot\", \"won't\":\"will not\", \"n't\":\" not\", \"'re\":\" are\", \"'s\":\" is\",\n",
    "    \"'d\":\" would\", \"'ll\":\" will\", \"'t\":\" not\", \"'ve\":\" have\", \"'m\":\" am\"\n",
    "}\n",
    "\n",
    "def _expand_contractions(text: str) -> str:\n",
    "    for k, v in CONTRACTIONS.items():\n",
    "        text = re.sub(k, v, text)\n",
    "    return text\n",
    "\n",
    "def _get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'): return wordnet.ADJ\n",
    "    if tag.startswith('V'): return wordnet.VERB\n",
    "    if tag.startswith('N'): return wordnet.NOUN\n",
    "    if tag.startswith('R'): return wordnet.ADV\n",
    "    return wordnet.NOUN\n",
    "\n",
    "def clean_text2(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Unescape HTML\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https?\\S+', ' ', text)\n",
    "\n",
    "    # Expand contractions (keeps negation words)\n",
    "    text = _expand_contractions(text)\n",
    "\n",
    "    # Keep emojis if you want sentiment info; here we drop non text/emoji:\n",
    "    # text = emoji.replace_emoji(text, replace=' EMOJI ')  # if using emoji lib\n",
    "\n",
    "    # Remove HTML tags if any\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Optional: join negation with following word to preserve scope\n",
    "    joined = []\n",
    "    skip_next = False\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "        if tok == \"not\" and i + 1 < len(tokens):\n",
    "            joined.append(f\"not_{tokens[i+1]}\")\n",
    "            skip_next = True\n",
    "        else:\n",
    "            joined.append(tok)\n",
    "    tokens = joined\n",
    "\n",
    "    # Remove punctuation tokens & digits\n",
    "    tokens = [t for t in tokens if any(c.isalpha() for c in t)]\n",
    "    tokens = [t.translate(str.maketrans('', '', string.punctuation)) for t in tokens]\n",
    "    tokens = [t for t in tokens if t]  # drop empties\n",
    "\n",
    "    # POS tagging for better lemmatization\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    tokens = [LEMMATIZER.lemmatize(w, _get_wordnet_pos(p)) for w, p in pos_tags]\n",
    "\n",
    "    # Stopwords AFTER lemmatization; keep negation tokens\n",
    "    tokens = [t for t in tokens if t not in STOP_WORDS or t.startswith(\"not_\")]\n",
    "\n",
    "    # Collapse whitespace\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d6c7b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>sentiment_str</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text2</th>\n",
       "      <th>cleaned_reviewText</th>\n",
       "      <th>clean_text3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>It is definitely not a watercolor book.</td>\n",
       "      <td>it is definitely not a watercolor book</td>\n",
       "      <td>definit watercolor book</td>\n",
       "      <td>definitely watercolor book</td>\n",
       "      <td>definitely nota watercolor book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>The paper bucked completely.</td>\n",
       "      <td>the paper bucked completely</td>\n",
       "      <td>paper buck complet</td>\n",
       "      <td>paper bucked completely</td>\n",
       "      <td>paper buck completely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>The pages honestly appear to be photo copies o...</td>\n",
       "      <td>the pages honestly appear to be photo copies o...</td>\n",
       "      <td>page honestli appear photo copi pictur</td>\n",
       "      <td>pages honestly appear photo copies pictures</td>\n",
       "      <td>page honestly appear photo copy picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>I say that bc if you look at the seal pics you...</td>\n",
       "      <td>i say that bc if you look at the seal pics you...</td>\n",
       "      <td>say bc look seal pic see tell tale line bottom...</td>\n",
       "      <td>say bc look seal pics see tell tale line botto...</td>\n",
       "      <td>say bc look seal pic see tell tale line bottom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>As someone who has made many photocopies of pa...</td>\n",
       "      <td>as someone who has made many photocopies of pa...</td>\n",
       "      <td>someon made mani photocopi page time could tri...</td>\n",
       "      <td>someone made many photocopies pages time could...</td>\n",
       "      <td>someone make many photocopy page time could tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                          title  \\\n",
       "0       1  Not a watercolor book! Seems like copies imo.   \n",
       "0       1  Not a watercolor book! Seems like copies imo.   \n",
       "0       1  Not a watercolor book! Seems like copies imo.   \n",
       "0       1  Not a watercolor book! Seems like copies imo.   \n",
       "0       1  Not a watercolor book! Seems like copies imo.   \n",
       "\n",
       "                                                text  \\\n",
       "0  It is definitely not a watercolor book.  The p...   \n",
       "0  It is definitely not a watercolor book.  The p...   \n",
       "0  It is definitely not a watercolor book.  The p...   \n",
       "0  It is definitely not a watercolor book.  The p...   \n",
       "0  It is definitely not a watercolor book.  The p...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
       "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
       "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
       "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
       "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
       "\n",
       "                        user_id               timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
       "\n",
       "   verified_purchase sentiment_str  sentiment  \\\n",
       "0               True      negative          0   \n",
       "0               True      negative          0   \n",
       "0               True      negative          0   \n",
       "0               True      negative          0   \n",
       "0               True      negative          0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0            It is definitely not a watercolor book.   \n",
       "0                       The paper bucked completely.   \n",
       "0  The pages honestly appear to be photo copies o...   \n",
       "0  I say that bc if you look at the seal pics you...   \n",
       "0  As someone who has made many photocopies of pa...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0             it is definitely not a watercolor book   \n",
       "0                        the paper bucked completely   \n",
       "0  the pages honestly appear to be photo copies o...   \n",
       "0  i say that bc if you look at the seal pics you...   \n",
       "0  as someone who has made many photocopies of pa...   \n",
       "\n",
       "                                         clean_text2  \\\n",
       "0                            definit watercolor book   \n",
       "0                                 paper buck complet   \n",
       "0             page honestli appear photo copi pictur   \n",
       "0  say bc look seal pic see tell tale line bottom...   \n",
       "0  someon made mani photocopi page time could tri...   \n",
       "\n",
       "                                  cleaned_reviewText  \\\n",
       "0                         definitely watercolor book   \n",
       "0                            paper bucked completely   \n",
       "0        pages honestly appear photo copies pictures   \n",
       "0  say bc look seal pics see tell tale line botto...   \n",
       "0  someone made many photocopies pages time could...   \n",
       "\n",
       "                                         clean_text3  \n",
       "0                    definitely nota watercolor book  \n",
       "0                              paper buck completely  \n",
       "0            page honestly appear photo copy picture  \n",
       "0  say bc look seal pic see tell tale line bottom...  \n",
       "0  someone make many photocopy page time could tr...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text2'] = df['sentence'].apply(clean_text)\n",
    "\n",
    "df['clean_text3'] = df['sentence'].apply(clean_text2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f5798006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5702983232924439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60      4744\n",
      "           1       0.39      0.36      0.37      3116\n",
      "           2       0.65      0.64      0.65      5917\n",
      "\n",
      "    accuracy                           0.57     13777\n",
      "   macro avg       0.54      0.54      0.54     13777\n",
      "weighted avg       0.57      0.57      0.57     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['clean_text3'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "svm_model = LinearSVC(class_weight='balanced')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5686288742106409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60      4744\n",
      "           1       0.39      0.36      0.37      3116\n",
      "           2       0.65      0.64      0.64      5917\n",
      "\n",
      "    accuracy                           0.57     13777\n",
      "   macro avg       0.54      0.54      0.54     13777\n",
      "weighted avg       0.57      0.57      0.57     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['clean_text2'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "svm_model = LinearSVC(class_weight='balanced')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22f427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890b7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8145d2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5684111199825796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60      4744\n",
      "           1       0.39      0.36      0.37      3116\n",
      "           2       0.65      0.64      0.64      5917\n",
      "\n",
      "    accuracy                           0.57     13777\n",
      "   macro avg       0.54      0.54      0.54     13777\n",
      "weighted avg       0.56      0.57      0.57     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "svm_model = LinearSVC(class_weight='balanced')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23006639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5639108659359803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59      4744\n",
      "           1       0.37      0.43      0.40      3116\n",
      "           2       0.67      0.61      0.64      5917\n",
      "\n",
      "    accuracy                           0.56     13777\n",
      "   macro avg       0.54      0.54      0.54     13777\n",
      "weighted avg       0.57      0.56      0.57     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8e702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c24f8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    # Join tokens back to text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "de9c3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_reviewText'] = df['sentence'].apply(lambda x: preprocess_text(x) if pd.notnull(x) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "042d29bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              definitely watercolor book\n",
       "0                                 paper bucked completely\n",
       "0             pages honestly appear photo copies pictures\n",
       "0       say bc look seal pics see tell tale line botto...\n",
       "0       someone made many photocopies pages time could...\n",
       "                              ...                        \n",
       "9999    short volume like rest series one also pages l...\n",
       "9999    necessary read earlier novels appreciate one e...\n",
       "9999    dr von igelfeld nearly sympathetic character o...\n",
       "9999    dr von igelfeld exploits lean towards absurd s...\n",
       "9999    unlike series particularly anxious read next b...\n",
       "Name: cleaned_reviewText, Length: 68881, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviewText'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e3ab04ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text2</th>\n",
       "      <th>cleaned_reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>definit watercolor book</td>\n",
       "      <td>definitely watercolor book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper buck complet</td>\n",
       "      <td>paper bucked completely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page honestli appear photo copi pictur</td>\n",
       "      <td>pages honestly appear photo copies pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say bc look seal pic see tell tale line bottom...</td>\n",
       "      <td>say bc look seal pics see tell tale line botto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>someon made mani photocopi page time could tri...</td>\n",
       "      <td>someone made many photocopies pages time could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>short volum like rest seri one also page long ...</td>\n",
       "      <td>short volume like rest series one also pages l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>necessari read earlier novel appreci one even ...</td>\n",
       "      <td>necessary read earlier novels appreciate one e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>dr von igelfeld nearli sympathet charact other...</td>\n",
       "      <td>dr von igelfeld nearly sympathetic character o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>dr von igelfeld exploit lean toward absurd seri</td>\n",
       "      <td>dr von igelfeld exploits lean towards absurd s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>unlik seri particularli anxiou read next book ...</td>\n",
       "      <td>unlike series particularly anxious read next b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68881 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text2  \\\n",
       "0                               definit watercolor book   \n",
       "0                                    paper buck complet   \n",
       "0                page honestli appear photo copi pictur   \n",
       "0     say bc look seal pic see tell tale line bottom...   \n",
       "0     someon made mani photocopi page time could tri...   \n",
       "...                                                 ...   \n",
       "9999  short volum like rest seri one also page long ...   \n",
       "9999  necessari read earlier novel appreci one even ...   \n",
       "9999  dr von igelfeld nearli sympathet charact other...   \n",
       "9999    dr von igelfeld exploit lean toward absurd seri   \n",
       "9999  unlik seri particularli anxiou read next book ...   \n",
       "\n",
       "                                     cleaned_reviewText  \n",
       "0                            definitely watercolor book  \n",
       "0                               paper bucked completely  \n",
       "0           pages honestly appear photo copies pictures  \n",
       "0     say bc look seal pics see tell tale line botto...  \n",
       "0     someone made many photocopies pages time could...  \n",
       "...                                                 ...  \n",
       "9999  short volume like rest series one also pages l...  \n",
       "9999  necessary read earlier novels appreciate one e...  \n",
       "9999  dr von igelfeld nearly sympathetic character o...  \n",
       "9999  dr von igelfeld exploits lean towards absurd s...  \n",
       "9999  unlike series particularly anxious read next b...  \n",
       "\n",
       "[68881 rows x 2 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['clean_text2', 'cleaned_reviewText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "94b4b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['cleaned_reviewText'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4331e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5594831966320679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      4744\n",
      "           1       0.38      0.35      0.36      3116\n",
      "           2       0.65      0.62      0.63      5917\n",
      "\n",
      "    accuracy                           0.56     13777\n",
      "   macro avg       0.53      0.53      0.53     13777\n",
      "weighted avg       0.56      0.56      0.56     13777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = LinearSVC(class_weight='balanced')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c3698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "95cbd032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_pipeline.pkl']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string, html\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Minimal cleaner as a transformer (so it’s serialized with the pipeline)\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        def clean(t):\n",
    "            if not isinstance(t, str): return \"\"\n",
    "            t = html.unescape(t).lower()\n",
    "            t = re.sub(r'http\\S+|www\\S+', ' ', t)\n",
    "            t = re.sub(r'<[^>]+>', ' ', t)\n",
    "            t = re.sub(r'\\d+', ' ', t)\n",
    "            t = t.translate(str.maketrans('', '', string.punctuation))\n",
    "            t = re.sub(r'\\s+', ' ', t).strip()\n",
    "            return t\n",
    "        return np.array([clean(x) for x in X])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"clean\", TextCleaner()),\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# X_text: your raw text column; y: labels (negative/neutral/positive)\n",
    "pipeline.fit(df['sentence'], y)\n",
    "joblib.dump(pipeline, \"sentiment_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1dc41648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;clean&#x27;, TextCleaner()),\n",
       "                (&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;clean&#x27;, ...), (&#x27;tfidf&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TextCleaner</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"clean__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"tfidf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">5000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"clf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('clean', TextCleaner()),\n",
       "                ('tfidf',\n",
       "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
       "                ('clf',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000))])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872f780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
